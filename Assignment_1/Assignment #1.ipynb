{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Ops Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from minibatch import iterate_minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 1a: Create two random 0-d tensors x and y of any distribution.\n",
    "# Create a TensorFlow object that returns x + y if x > y, and x - y otherwise.\n",
    "# Hint: look up tf.cond()\n",
    "# I do the first problem for you\n",
    "###############################################################################\n",
    "x = tf.random_uniform([])  # Empty array as shape creates a scalar.\n",
    "y = tf.random_uniform([])\n",
    "out = tf.cond(tf.less(x, y), lambda: tf.add(x, y), lambda: tf.subtract(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 1b: Create two 0-d tensors x and y randomly selected from -1 and 1.\n",
    "# Return x + y if x < y, x - y if x > y, 0 otherwise.\n",
    "# Hint: Look up tf.case().\n",
    "###############################################################################\n",
    "x = tf.random_uniform([],minval=-1,maxval=1)\n",
    "y = tf.random_uniform([],minval=-1,maxval=1)\n",
    "out = tf.case([(tf.less(x,y),lambda: tf.add(x,y)),(tf.less(y,x),lambda: tf.subtract(x,y))],default=\\\n",
    "              lambda: tf.constant(0,dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 1c: Create the tensor x of the value [[0, -2, -1], [0, 1, 2]] \n",
    "# and y as a tensor of zeros with the same shape as x.\n",
    "# Return a boolean tensor that yields Trues if x equals y element-wise.\n",
    "# Hint: Look up tf.equal().\n",
    "###############################################################################\n",
    "x = tf.constant([[0,-2,-1],[0,1,2]],name=\"x\")\n",
    "y = tf.ones_like(x)\n",
    "out = tf.equal(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 1d: Create the tensor x of value \n",
    "# [29.05088806,  27.61298943,  31.19073486,  29.35532951,\n",
    "#  30.97266006,  26.67541885,  38.08450317,  20.74983215,\n",
    "#  34.94445419,  34.45999146,  29.06485367,  36.01657104,\n",
    "#  27.88236427,  20.56035233,  30.20379066,  29.51215172,\n",
    "#  33.71149445,  28.59134293,  36.05556488,  28.66994858].\n",
    "# Get the indices of elements in x whose values are greater than 30.\n",
    "# Hint: Use tf.where().\n",
    "# Then extract elements whose values are greater than 30.\n",
    "# Hint: Use tf.gather().\n",
    "###############################################################################\n",
    "x = tf.constant([29.05088806,  27.61298943,  31.19073486,  29.35532951,\n",
    "                30.97266006,  26.67541885,  38.08450317,  20.74983215,\n",
    "                34.94445419,  34.45999146,  29.06485367,  36.01657104,\n",
    "                27.88236427,  20.56035233,  30.20379066,  29.51215172,\n",
    "                33.71149445,  28.59134293,  36.05556488,  28.66994858],name=\"x\")\n",
    "out1 = tf.where(x > 30)\n",
    "out2 = tf.gather(x,out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Sanity Check\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print out2.eval().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 1e: Create a diagnoal 2-d tensor of size 6 x 6 with the diagonal values of 1,\n",
    "# 2, ..., 6\n",
    "# Hint: Use tf.range() and tf.diag().\n",
    "###############################################################################\n",
    "diagonal = tf.range(start=1,limit=7,delta=1)\n",
    "out = tf.diag(diagonal)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print out.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 1f: Create a random 2-d tensor of size 10 x 10 from any distribution.\n",
    "# Calculate its determinant.\n",
    "# Hint: Look at tf.matrix_determinant().\n",
    "###############################################################################\n",
    "matrix = tf.random_normal(shape=[10,10],stddev=1.0,mean=0)\n",
    "out = tf.matrix_determinant(matrix)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print out.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 1g: Create tensor x with value [5, 2, 3, 5, 10, 6, 2, 3, 4, 2, 1, 1, 0, 9].\n",
    "# Return the unique elements in x\n",
    "# Hint: use tf.unique(). Keep in mind that tf.unique() returns a tuple.\n",
    "###############################################################################\n",
    "vector = tf.Variable(tf.constant([5, 2, 3, 5, 10, 6, 2, 3, 4, 2, 1, 1, 0, 9]),name=\"vector\")\n",
    "out = tf.unique(vector)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(vector.initializer)\n",
    "    print out[0].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# 1h: Create two tensors x and y of shape 300 from any normal distribution,\n",
    "# as long as they are from the same distribution.\n",
    "# Use tf.less() and tf.select() to return:\n",
    "# - The mean squared error of (x - y) if the average of all elements in (x - y)\n",
    "#   is negative, or\n",
    "# - The sum of absolute value of all elements in the tensor (x - y) otherwise.\n",
    "# Hint: see the Huber loss function in the lecture slides 3.\n",
    "###############################################################################\n",
    "x = tf.Variable(tf.random_normal(shape=[300,300]),name=\"x\")\n",
    "y = tf.Variable(tf.random_normal(shape=[300,300]),name=\"y\")\n",
    "condition = tf.less(tf.reduce_mean(x - y),0)\n",
    "f1 = tf.square(tf.subtract(x,y))\n",
    "f2 = tf.reduce_sum(tf.abs(x - y))\n",
    "out = tf.cond(condition,lambda:f1,lambda:f2)\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print out.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../../Dataset/MNIST/train.csv')\n",
    "print data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "\n",
       "[2 rows x 785 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 10)\n"
     ]
    }
   ],
   "source": [
    "label_ = data.pop('label')\n",
    "label = pd.get_dummies(label_)\n",
    "print label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWMAAAFjCAYAAADowmrhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngyo/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c70eb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data.iloc[0,:].reshape(28,28),cmap='gray')\n",
    "print np.argmax(label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29400, 784) (29400, 10)\n",
      "(12600, 784) (12600, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(data,label,test_size=0.3,random_state=7)\n",
    "X_train,X_test,y_train,y_test = X_train.values,X_test.values,y_train.values,y_test.values\n",
    "print X_train.shape,y_train.shape\n",
    "print X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Connected Neural Network Using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_samples,n_features = X_train.shape\n",
    "num_samples_cv = X_test.shape[0]\n",
    "num_classes, num_hidden = 10,512\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,shape=[None,n_features],name='X')\n",
    "y = tf.placeholder(tf.float32,shape=[None,num_classes],name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"W1/read:0\", shape=(784, 512), dtype=float32) Tensor(\"b1/read:0\", shape=(1, 512), dtype=float32)\n",
      "Tensor(\"W2/read:0\", shape=(512, 10), dtype=float32) Tensor(\"b2/read:0\", shape=(1, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "W1 = tf.Variable(tf.random_normal(shape=[n_features,num_hidden]),name='W1')\n",
    "b1 = tf.Variable(tf.zeros([1,num_hidden]),name='b1')\n",
    "W2 = tf.Variable(tf.random_normal(shape=[num_hidden,num_classes]),name='W2')\n",
    "b2 = tf.Variable(tf.zeros([1,num_classes]),name='b2')\n",
    "print W1,b1\n",
    "print W2,b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## First Activation\n",
    "z1 = tf.matmul(X,W1) + b1\n",
    "a1 = tf.nn.relu(z1)\n",
    "## Second Activation\n",
    "logits = tf.matmul(a1,W2) + b2\n",
    "#ypred = tf.sigmoid(logits)\n",
    "## Getting the accuracy\n",
    "correct_preds = tf.equal(tf.argmax(logits,1),tf.argmax(y,1))\n",
    "acc = tf.reduce_mean(tf.cast(correct_preds,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=y)\n",
    "loss = tf.reduce_mean(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tTraining Loss: 920149.325485\t Trainig Acc: 0.861258506775\tCross Validation Acc: 0.909444391727\n",
      "Epoch: 2\tTraining Loss: 119870.398826\t Trainig Acc: 0.932993173599\tCross Validation Acc: 0.92158728838\n",
      "Epoch: 3\tTraining Loss: 62767.2834234\t Trainig Acc: 0.952482998371\tCross Validation Acc: 0.929603099823\n",
      "Epoch: 4\tTraining Loss: 36762.6611585\t Trainig Acc: 0.965578258038\tCross Validation Acc: 0.932142853737\n",
      "Epoch: 5\tTraining Loss: 23100.5645252\t Trainig Acc: 0.973401427269\tCross Validation Acc: 0.932539701462\n",
      "Epoch: 6\tTraining Loss: 13855.3783901\t Trainig Acc: 0.979659855366\tCross Validation Acc: 0.932936429977\n",
      "Epoch: 7\tTraining Loss: 9387.04428804\t Trainig Acc: 0.983605444431\tCross Validation Acc: 0.933809459209\n",
      "Epoch: 8\tTraining Loss: 6358.75797432\t Trainig Acc: 0.987108945847\tCross Validation Acc: 0.934444367886\n",
      "Epoch: 9\tTraining Loss: 3940.54669224\t Trainig Acc: 0.990170001984\tCross Validation Acc: 0.936428487301\n",
      "Epoch: 10\tTraining Loss: 2885.47919615\t Trainig Acc: 0.992448985577\tCross Validation Acc: 0.935555458069\n",
      "Epoch: 11\tTraining Loss: 2082.90083507\t Trainig Acc: 0.993367433548\tCross Validation Acc: 0.937936425209\n",
      "Epoch: 12\tTraining Loss: 1255.30486976\t Trainig Acc: 0.995680332184\tCross Validation Acc: 0.937539517879\n",
      "Epoch: 13\tTraining Loss: 827.254880231\t Trainig Acc: 0.996564567089\tCross Validation Acc: 0.938650727272\n",
      "Epoch: 14\tTraining Loss: 492.678653547\t Trainig Acc: 0.997516989708\tCross Validation Acc: 0.935555458069\n",
      "Epoch: 15\tTraining Loss: 424.634447491\t Trainig Acc: 0.997789025307\tCross Validation Acc: 0.936984121799\n",
      "Epoch: 16\tTraining Loss: 296.451279238\t Trainig Acc: 0.998231351376\tCross Validation Acc: 0.938015818596\n",
      "Epoch: 17\tTraining Loss: 288.290055664\t Trainig Acc: 0.998299300671\tCross Validation Acc: 0.93857139349\n",
      "Epoch: 18\tTraining Loss: 212.878633543\t Trainig Acc: 0.998673498631\tCross Validation Acc: 0.93976187706\n",
      "Epoch: 19\tTraining Loss: 128.738712679\t Trainig Acc: 0.999183595181\tCross Validation Acc: 0.939444482327\n",
      "Epoch: 20\tTraining Loss: 89.6635654401\t Trainig Acc: 0.999251723289\tCross Validation Acc: 0.939761817455\n",
      "Epoch: 21\tTraining Loss: 150.888562877\t Trainig Acc: 0.998741388321\tCross Validation Acc: 0.93873000145\n",
      "Epoch: 22\tTraining Loss: 106.022237781\t Trainig Acc: 0.999081552029\tCross Validation Acc: 0.939444363117\n",
      "Epoch: 23\tTraining Loss: 56.7967431396\t Trainig Acc: 0.999081552029\tCross Validation Acc: 0.939444422722\n",
      "Epoch: 24\tTraining Loss: 71.3211899716\t Trainig Acc: 0.99918371439\tCross Validation Acc: 0.940476119518\n",
      "Epoch: 25\tTraining Loss: 125.176980599\t Trainig Acc: 0.999115586281\tCross Validation Acc: 0.940396785736\n",
      "Epoch: 26\tTraining Loss: 73.9162303805\t Trainig Acc: 0.999455749989\tCross Validation Acc: 0.93976187706\n",
      "Epoch: 27\tTraining Loss: 25.1484981053\t Trainig Acc: 0.999727845192\tCross Validation Acc: 0.939206302166\n",
      "Epoch: 28\tTraining Loss: 21.6196681261\t Trainig Acc: 0.999761879444\tCross Validation Acc: 0.938809514046\n",
      "Epoch: 29\tTraining Loss: 21.8260546178\t Trainig Acc: 0.999693870544\tCross Validation Acc: 0.939285635948\n",
      "Epoch: 30\tTraining Loss: 29.6412500143\t Trainig Acc: 0.99969381094\tCross Validation Acc: 0.93857139349\n",
      "Epoch: 31\tTraining Loss: 40.5776367188\t Trainig Acc: 0.999625921249\tCross Validation Acc: 0.938888847828\n",
      "Epoch: 32\tTraining Loss: 46.0483895838\t Trainig Acc: 0.999523758888\tCross Validation Acc: 0.939682424068\n",
      "Epoch: 33\tTraining Loss: 10.5735048089\t Trainig Acc: 0.999897837639\tCross Validation Acc: 0.939206242561\n",
      "Epoch: 34\tTraining Loss: 2.00274772224\t Trainig Acc: 0.999863922596\tCross Validation Acc: 0.939523756504\n",
      "Epoch: 35\tTraining Loss: 12.2948596332\t Trainig Acc: 0.999829888344\tCross Validation Acc: 0.93936496973\n",
      "Epoch: 36\tTraining Loss: 30.6345791817\t Trainig Acc: 0.999795913696\tCross Validation Acc: 0.938809394836\n",
      "Epoch: 37\tTraining Loss: 12.4652617648\t Trainig Acc: 0.999761879444\tCross Validation Acc: 0.939603090286\n",
      "Epoch: 38\tTraining Loss: 9.22298842669\t Trainig Acc: 0.999863922596\tCross Validation Acc: 0.939841210842\n",
      "Epoch: 39\tTraining Loss: 0.0\t Trainig Acc: 1.0\tCross Validation Acc: 0.939841210842\n",
      "Epoch: 40\tTraining Loss: 0.0\t Trainig Acc: 1.0\tCross Validation Acc: 0.939841210842\n",
      "Reached Minima....\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    prev_cost = 0.0\n",
    "    Writer = tf.summary.FileWriter('./graphs',sess.graph)\n",
    "    for epoch in range(n_epochs):\n",
    "        cost,accuracy_train,accuracy_cv = 0.0,[],[]\n",
    "        ## Training Epochs\n",
    "        for i in range(num_samples/batch_size):\n",
    "            cur_batch,next_batch = i*batch_size,(i+1)*batch_size\n",
    "            x_batch,y_batch = X_train[cur_batch:next_batch,:],y_train[cur_batch:next_batch,:]\n",
    "            _,l,acc_train = sess.run([optimizer,loss,acc],feed_dict={X:x_batch,y:y_batch})\n",
    "            accuracy_train.append(acc_train)\n",
    "            cost += l\n",
    "        ## Cross validation epochs\n",
    "        for i in range(num_samples_cv/batch_size):\n",
    "            cur_batch,next_batch = i*batch_size,(i+1)*batch_size\n",
    "            x_batch,y_batch = X_test[cur_batch:next_batch,:],y_test[cur_batch:next_batch,:]\n",
    "            acc_cv = sess.run(acc,feed_dict={X:x_batch,y:y_batch})\n",
    "            accuracy_cv.append(acc_cv)\n",
    "        print 'Epoch: {}\\tTraining Loss: {}\\t Trainig Acc: {}\\tCross Validation Acc: {}'.\\\n",
    "        format(epoch+1,cost,np.mean(accuracy_train),np.mean(accuracy_cv))\n",
    "        if abs(cost - prev_cost) <= 1e-5:\n",
    "            print 'Reached Minima....'\n",
    "            break\n",
    "        prev_cost = cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Convolutional Neural Network Using Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib import learn\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "from tensorflow.contrib.learn.python import SKCompat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29400, 784) (29400,)\n",
      "(12600, 784) (12600,)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../../Dataset/MNIST/train.csv')\n",
    "X_train,X_test,y_train,y_test = train_test_split(data.iloc[:,1:],data.iloc[:,0],test_size=0.3,random_state=7)\n",
    "X_train,y_train = np.asarray(X_train),np.asarray(y_train,np.int32)\n",
    "X_test,y_test = np.asarray(X_test),np.asarray(y_test,np.int32)\n",
    "print X_train.shape,y_train.shape\n",
    "print X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64 int32\n",
      "int64 int32\n"
     ]
    }
   ],
   "source": [
    "print X_train.dtype,y_train.dtype\n",
    "print X_test.dtype,y_test.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the CNN MNIST Classifier\n",
    "Let's build a model to classify the images in the MNIST dataset using the following CNN architecture:\n",
    "\n",
    "1. Convolutional Layer #1: Applies 32 5x5 filters (extracting 5x5-pixel subregions), with ReLU activation function\n",
    "2. Pooling Layer #1: Performs max pooling with a 2x2 filter and stride of 2 (which specifies that pooled regions do not overlap)\n",
    "3. Convolutional Layer #2: Applies 64 5x5 filters, with ReLU activation function\n",
    "4. Pooling Layer #2: Again, performs max pooling with a 2x2 filter and stride of 2\n",
    "5. Dense Layer #1: 1,024 neurons, with dropout regularization rate of 0.4 (probability of 0.4 that any given element will be dropped during training)\n",
    "6. Dense Layer #2 (Logits Layer): 10 neurons, one for each digit target class (0–9).\n",
    "\n",
    "The tf.layers module contains methods to create each of the three layer types above:\n",
    "* conv2d(). Constructs a two-dimensional convolutional layer. Takes number of filters, filter kernel size, padding, and activation function as arguments.\n",
    "* max_pooling2d(). Constructs a two-dimensional pooling layer using the max-pooling algorithm. Takes pooling filter size and stride as arguments.\n",
    "* dense(). Constructs a dense layer. Takes number of neurons and activation function as arguments.\n",
    "\n",
    "Each of these methods accepts a tensor as input and returns a transformed tensor as output. This makes it easy to connect one layer to another: just take the output from one layer-creation method and supply it as input to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    ## Input layer\n",
    "    ## -1 implies batch size is dynamic and liable to change\n",
    "    ## It should be computed on the go\n",
    "    ## Convolution/Pooling layers requires input tensor of shape [batch_size,image_width, image_height,channels]\n",
    "    input_layer = tf.reshape(features,[-1,28,28,1])\n",
    "    \n",
    "    ## Convolution Layer 1\n",
    "    ## Padding = 'same' implies that shape(input_tensor) == shape(output_tensor)\n",
    "    ## Number of filters will determine the depth of the output (here 32)\n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=32,\n",
    "        kernel_size=[5,5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    ## Pooling Layer 1\n",
    "    ## pool_size = [width,height]\n",
    "    ## Output after pooling == [batch_size,image_width/2, image_height/2,n_filters]\n",
    "    pool1 = tf.layers.max_pooling2d(conv1,pool_size=[2,2],strides=2)\n",
    "    \n",
    "    ## Convolution Layer 2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=64,\n",
    "        kernel_size=[5,5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "    \n",
    "    ## Pooling Layer 2\n",
    "    ## Each pooling layer decreases the size of input by 50% (2x2 pooling)\n",
    "    pool2 = tf.layers.max_pooling2d(conv2,pool_size=[2,2],strides=2)\n",
    "    \n",
    "    ## Dense Layer, takes input tensor of shape [batch_size,n_features]\n",
    "    ## Dense layer performs classification on the features extracted by Conv Layers\n",
    "    pool2_flat = tf.reshape(pool2,[-1,7*7*64])    ## Dense Layer requires vector input\n",
    "    dense = tf.layers.dense(inputs=pool2_flat,units=1024,activation=tf.nn.relu)\n",
    "    \n",
    "    ## Dropout Layer, performs a 40% dropout\n",
    "    ## mode == learn.ModeKeys.TRAIN specifies if the model is running in training mode\n",
    "    ## Dropout is applied only in the training mode\n",
    "    dropout = tf.layers.dropout(inputs=dense,rate=0.4,training=mode==learn.ModeKeys.TRAIN)\n",
    "    \n",
    "    ## Output Layer\n",
    "    logits = tf.layers.dense(inputs=dropout,units=10)\n",
    "    \n",
    "    loss=None\n",
    "    train_op=None\n",
    "    \n",
    "    if mode != learn.ModeKeys.INFER:\n",
    "        one_hot_labels = tf.one_hot(indices=tf.cast(labels,tf.int32),depth=10)\n",
    "        loss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels,logits=logits)\n",
    "        \n",
    "    if mode == learn.ModeKeys.TRAIN:\n",
    "        train_op = tf.contrib.layers.optimize_loss(loss=loss,global_step=tf.contrib.framework.get_global_step(),\n",
    "                                                  learning_rate=0.001,optimizer=\"SGD\")\n",
    "    \n",
    "    ## Generating the Predictions\n",
    "    predictions = {\"classes\":tf.argmax(input=logits,axis=1),\n",
    "                  \"probabilities\":tf.nn.softmax(logits=logits,name=\"softmax_tensor\")}\n",
    "    \n",
    "    ## Returning the parameters calculated in a Model Object\n",
    "    return model_fn_lib.ModelFnOps(mode=mode,predictions=predictions,loss=loss,train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': None, '_environment': 'local', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x12cc08f90>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': ''}\n"
     ]
    }
   ],
   "source": [
    "## Creating the Estimator\n",
    "model_estimator = SKCompat(learn.Estimator(model_fn=cnn_model_fn,model_dir=\n",
    "                                           '/Users/najeebkhan/Desktop/GitHub/Tensorflow-CS20SI/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Since CNNs can take quite long to train, we can set up checkpoints\n",
    "''' We store a dict of the tensors we want to log in tensors_to_log. \n",
    "    Each key is a label of our choice that will be printed in the log\n",
    "    output, and the corresponding label is the name of a Tensor in the\n",
    "    TensorFlow graph'''\n",
    "tensors_to_log = {\"probabilites\":\"softmax_tensor\"}\n",
    "logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log,every_n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /Users/najeebkhan/Desktop/GitHub/Tensorflow-CS20SI/model.ckpt.\n",
      "INFO:tensorflow:loss = 34.4749, step = 1\n",
      "INFO:tensorflow:probabilites = [[  2.04357245e-18   1.11547105e-10   1.56586047e-03   1.87124165e-08\n",
      "    2.37006595e-14   1.75991289e-07   9.69352280e-19   8.64690602e-01\n",
      "    1.33743316e-01   4.82452966e-12]\n",
      " [  1.49379734e-30   1.97988009e-16   1.00000000e+00   2.52188997e-34\n",
      "    2.76157862e-26   0.00000000e+00   8.31696201e-31   9.18951680e-30\n",
      "    1.42317137e-12   3.38044766e-11]\n",
      " [  5.21948200e-28   4.08281871e-08   1.11721565e-08   3.65208578e-17\n",
      "    9.65917661e-18   1.93993189e-19   3.87684897e-22   2.59323674e-09\n",
      "    1.00000000e+00   2.54747537e-18]\n",
      " [  2.50805186e-22   2.19366994e-30   1.00000000e+00   1.90490870e-11\n",
      "    2.88696901e-23   9.48707924e-16   1.04424324e-31   3.19650029e-10\n",
      "    1.96888689e-13   2.09469562e-08]\n",
      " [  1.78554115e-17   7.18399173e-21   6.29355013e-02   8.03368688e-01\n",
      "    2.16382045e-06   3.31052509e-03   8.74537378e-15   1.30344093e-01\n",
      "    3.80629790e-05   8.89555849e-07]\n",
      " [  1.40863499e-37   2.27937926e-28   1.00000000e+00   2.18813548e-24\n",
      "    2.28524170e-14   1.02247117e-19   1.25187153e-23   2.87671807e-19\n",
      "    1.47648751e-18   5.56048331e-26]\n",
      " [  1.25746403e-14   1.21697144e-17   5.04713382e-09   1.87578808e-16\n",
      "    1.86754006e-25   9.15756389e-14   1.76642431e-34   9.08351866e-12\n",
      "    4.08748128e-05   9.99959111e-01]\n",
      " [  5.71269465e-23   2.67326762e-18   1.00000000e+00   4.55362137e-37\n",
      "    5.07350057e-30   4.91255196e-29   0.00000000e+00   5.85010386e-17\n",
      "    1.17294945e-18   4.64321125e-26]\n",
      " [  5.98300007e-36   9.19188657e-18   1.00000000e+00   7.49886481e-22\n",
      "    8.52137845e-15   1.00313808e-20   0.00000000e+00   1.69129732e-18\n",
      "    2.69289295e-22   3.90875883e-08]\n",
      " [  2.98657100e-26   1.00082708e-17   1.00000000e+00   5.21617807e-28\n",
      "    5.74992135e-25   1.90745470e-25   5.98564345e-15   3.97353049e-13\n",
      "    7.48063500e-15   1.63684257e-19]\n",
      " [  6.84481132e-21   3.30381985e-19   6.30045251e-04   1.31702802e-06\n",
      "    3.09168448e-17   1.90917765e-23   3.99819686e-29   3.31795920e-04\n",
      "    9.99036908e-01   2.02205765e-13]\n",
      " [  8.04800155e-19   8.18279125e-11   4.87984698e-06   1.71501767e-02\n",
      "    3.11315575e-26   6.06900574e-09   0.00000000e+00   5.06641218e-18\n",
      "    9.82844949e-01   3.10072864e-15]\n",
      " [  1.25441859e-20   7.36097898e-03   7.70695329e-01   1.44035678e-26\n",
      "    1.18909208e-20   2.92067677e-26   7.99925012e-29   2.15009809e-01\n",
      "    6.12614024e-03   8.07662029e-04]\n",
      " [  4.27257266e-26   5.07647856e-18   9.89652097e-01   7.65738306e-11\n",
      "    3.25920406e-19   1.41142412e-27   9.71800037e-38   5.61407880e-08\n",
      "    1.03479018e-02   7.37689549e-15]\n",
      " [  1.36025457e-20   2.89895603e-14   1.00000000e+00   2.59856689e-22\n",
      "    9.89671669e-13   7.41697783e-17   3.80459721e-34   6.55646558e-29\n",
      "    4.73768600e-24   7.06309329e-16]\n",
      " [  5.37400244e-27   1.14264786e-18   9.50897187e-02   7.24117571e-11\n",
      "    1.65082056e-17   2.32869877e-15   4.00748440e-23   1.36316951e-14\n",
      "    9.04786527e-01   1.23677659e-04]\n",
      " [  2.44545952e-21   3.41071743e-24   1.00035185e-03   1.50085023e-14\n",
      "    9.98999655e-01   5.08873102e-14   8.13249921e-25   7.63252661e-09\n",
      "    5.58377953e-12   1.37554146e-09]\n",
      " [  1.10461040e-19   4.33165105e-17   3.63153114e-04   9.99599278e-01\n",
      "    4.74387952e-20   3.43737411e-05   1.97048430e-23   8.67207833e-11\n",
      "    8.77870548e-07   2.38620851e-06]\n",
      " [  5.09311911e-17   1.72859960e-04   3.72409151e-04   9.44646399e-21\n",
      "    2.23367568e-25   3.41645792e-28   5.30285243e-27   9.85710144e-01\n",
      "    1.20183308e-10   1.37446225e-02]\n",
      " [  7.82578388e-20   8.23338980e-27   3.83866184e-14   1.03680248e-13\n",
      "    3.00909708e-35   2.93523649e-26   0.00000000e+00   1.67507542e-14\n",
      "    1.00000000e+00   4.27755943e-26]\n",
      " [  1.24292276e-14   6.51017087e-12   9.97086704e-01   4.48645010e-10\n",
      "    2.98990585e-12   2.18869997e-28   2.76347239e-22   2.28493573e-05\n",
      "    2.89045484e-03   4.68700545e-13]\n",
      " [  9.76130496e-17   1.29962213e-15   2.85234142e-10   1.89361314e-19\n",
      "    0.00000000e+00   3.85293600e-29   3.90276643e-32   2.41421355e-24\n",
      "    1.00000000e+00   1.28145153e-30]\n",
      " [  5.04704985e-35   4.96723275e-34   9.98297870e-01   2.67375922e-12\n",
      "    2.44877016e-22   1.43424846e-19   2.93710139e-33   1.70210900e-03\n",
      "    3.12245407e-09   5.81147473e-33]\n",
      " [  2.22753358e-31   5.63527903e-13   9.99995947e-01   7.72512643e-17\n",
      "    5.76045762e-14   2.00581558e-18   7.77467389e-17   4.32843343e-08\n",
      "    8.96688377e-08   3.96904807e-06]\n",
      " [  7.78632280e-12   4.07159284e-08   2.80129183e-02   9.21022831e-08\n",
      "    1.10257618e-19   7.15237416e-15   3.18170438e-21   1.33182018e-17\n",
      "    9.71986949e-01   4.44908856e-08]\n",
      " [  5.68603915e-26   2.30846015e-21   2.70704902e-03   9.97292936e-01\n",
      "    9.58963464e-11   1.78288089e-13   7.90800365e-32   2.13019019e-31\n",
      "    6.35790655e-14   3.55880978e-22]\n",
      " [  1.91730486e-11   4.87777245e-13   6.50676072e-01   2.48124820e-07\n",
      "    7.20540157e-17   1.98116768e-38   1.52076619e-29   1.54561364e-10\n",
      "    3.49323660e-01   5.87395868e-14]\n",
      " [  4.90144509e-15   1.00229770e-01   7.60306656e-01   1.74439344e-06\n",
      "    1.44937767e-05   1.59890514e-12   4.41483297e-21   3.20110258e-11\n",
      "    1.39446467e-01   8.86242390e-07]\n",
      " [  1.14604854e-14   4.58799382e-22   9.75149691e-01   5.26330668e-09\n",
      "    5.28625094e-07   1.15290805e-19   0.00000000e+00   5.47087780e-08\n",
      "    2.48488672e-02   7.65375887e-07]\n",
      " [  1.06219477e-22   1.47432825e-38   1.00000000e+00   8.23772468e-27\n",
      "    3.76421137e-23   1.32732339e-16   1.45852235e-27   7.60765697e-31\n",
      "    3.55513925e-23   3.54983317e-12]\n",
      " [  3.33849564e-32   4.05811210e-18   2.21667251e-05   1.51687528e-13\n",
      "    1.16797427e-29   6.80655584e-21   9.22301337e-18   1.79225018e-34\n",
      "    9.99977827e-01   2.31187869e-20]\n",
      " [  8.13390411e-10   3.05119045e-07   1.73183841e-13   3.22151257e-26\n",
      "    7.52864071e-30   3.42652335e-26   0.00000000e+00   6.33613786e-11\n",
      "    1.16359113e-24   9.99999642e-01]\n",
      " [  6.79359133e-15   2.80311310e-13   2.20474085e-05   9.98549879e-01\n",
      "    3.47247260e-05   2.26917678e-06   1.85666954e-15   5.50740321e-11\n",
      "    1.61307442e-04   1.22976152e-03]\n",
      " [  0.00000000e+00   4.01842257e-17   9.81963158e-01   5.95694350e-04\n",
      "    2.88088640e-34   1.81936166e-16   2.39162019e-27   9.92834703e-10\n",
      "    1.74392499e-02   1.81948212e-06]\n",
      " [  2.71798862e-32   6.18086290e-28   1.00000000e+00   5.41892864e-10\n",
      "    5.68433761e-19   2.29947826e-25   3.69062489e-11   2.20283982e-11\n",
      "    2.62335527e-16   2.25355853e-13]\n",
      " [  8.81995480e-24   1.99957650e-09   2.76302129e-01   1.00778885e-09\n",
      "    5.02299764e-12   2.80702017e-23   1.91876024e-17   8.36465230e-10\n",
      "    7.22394705e-01   1.30311283e-03]\n",
      " [  3.93368603e-26   1.81085336e-09   9.99999404e-01   1.08009122e-10\n",
      "    1.27600597e-09   3.79347739e-07   2.54856650e-15   1.88158765e-07\n",
      "    4.64711203e-09   1.12688019e-11]\n",
      " [  2.33530789e-03   3.48962698e-26   9.96951699e-01   7.12266716e-04\n",
      "    5.18873696e-16   6.40885958e-07   5.56586397e-27   1.04410584e-10\n",
      "    2.19138053e-18   2.63405227e-08]\n",
      " [  4.18100029e-01   5.53889871e-01   2.52861820e-09   9.28249619e-08\n",
      "    3.15345194e-10   3.02757542e-07   7.11211196e-24   2.80096456e-02\n",
      "    6.53230998e-08   4.43906058e-11]\n",
      " [  1.91999955e-19   5.84523653e-23   5.27774100e-04   1.93260664e-14\n",
      "    1.31974243e-17   2.54070073e-23   2.68774249e-33   1.10699372e-24\n",
      "    8.84744833e-10   9.99472201e-01]\n",
      " [  1.27530985e-36   7.60563695e-16   9.01013181e-24   5.48472448e-11\n",
      "    5.30526968e-19   6.46563032e-26   6.95148163e-30   8.62130727e-16\n",
      "    9.99997616e-01   2.34565368e-06]\n",
      " [  6.57332993e-25   8.36059069e-11   1.12442824e-04   9.99446571e-01\n",
      "    3.14247238e-18   3.27354845e-11   5.12141273e-22   4.17951902e-04\n",
      "    2.33334454e-08   2.29973757e-05]\n",
      " [  6.94103673e-26   8.19930842e-12   5.59811169e-16   1.47896984e-09\n",
      "    2.35961115e-29   2.74291197e-23   6.45413914e-38   5.02328376e-13\n",
      "    9.97389019e-01   2.61103408e-03]\n",
      " [  8.25764841e-19   1.79177538e-15   1.19759647e-17   1.51500557e-04\n",
      "    1.07111054e-22   3.61576925e-17   6.33912156e-25   4.09447809e-09\n",
      "    9.29738045e-01   7.01104328e-02]\n",
      " [  3.56843209e-19   3.33593468e-23   3.88049702e-05   1.30573634e-18\n",
      "    9.20404615e-35   9.14270048e-28   9.90396532e-27   2.27707915e-24\n",
      "    9.99961138e-01   3.10734999e-13]\n",
      " [  1.21396849e-20   0.00000000e+00   2.95876879e-09   2.36433076e-18\n",
      "    2.64001074e-23   1.68175000e-18   3.31351295e-16   7.63308305e-11\n",
      "    1.00000000e+00   5.66539749e-26]\n",
      " [  1.20875717e-33   5.52058509e-24   1.00000000e+00   4.61397799e-16\n",
      "    1.67305411e-33   4.77195238e-15   5.05098547e-37   5.94331319e-26\n",
      "    5.40656759e-30   2.24116115e-10]\n",
      " [  3.75016638e-15   5.37534181e-18   1.00000000e+00   2.75172326e-20\n",
      "    6.32708887e-24   1.48079356e-30   3.86182773e-27   2.82650973e-24\n",
      "    1.41194212e-09   1.62441779e-11]\n",
      " [  5.54975006e-24   6.58293753e-10   2.15133724e-07   3.53595737e-04\n",
      "    1.85780770e-30   3.80189335e-16   3.57330374e-25   9.99646187e-01\n",
      "    4.95822764e-15   1.52671907e-12]\n",
      " [  5.89560884e-14   2.20826301e-20   2.28335830e-06   9.99995351e-01\n",
      "    4.25925753e-17   1.20725397e-18   1.12666691e-34   5.92749937e-20\n",
      "    2.14522359e-15   2.33309243e-06]\n",
      " [  8.06292040e-21   6.64175381e-11   7.32035266e-11   3.32456429e-22\n",
      "    1.87054439e-25   4.40887307e-21   0.00000000e+00   3.02714150e-04\n",
      "    5.82320853e-14   9.99697328e-01]\n",
      " [  3.99072594e-28   1.62164103e-26   1.00000000e+00   1.90777631e-31\n",
      "    1.88260960e-32   2.01682583e-26   2.96327572e-24   3.81009894e-13\n",
      "    6.80710877e-10   6.79218196e-21]\n",
      " [  1.98430893e-27   2.69493739e-24   9.99993086e-01   9.94763191e-13\n",
      "    2.84901047e-10   4.22562079e-16   3.92701424e-36   2.61805867e-16\n",
      "    6.90449315e-06   2.41513945e-14]\n",
      " [  2.66175451e-18   1.25943056e-19   3.04612172e-07   2.04416981e-04\n",
      "    2.03513831e-19   8.27307244e-13   9.92288760e-30   1.00030458e-13\n",
      "    1.81567648e-05   9.99777138e-01]\n",
      " [  2.29414241e-21   8.56320810e-08   3.67644399e-01   1.94820764e-08\n",
      "    2.29953563e-17   5.79836185e-27   9.04181089e-24   5.02471983e-01\n",
      "    1.29883558e-01   3.39303477e-20]\n",
      " [  1.00677180e-21   2.42702287e-30   1.00000000e+00   6.91216367e-19\n",
      "    7.99561526e-27   4.39206444e-26   3.41745811e-30   1.04636305e-19\n",
      "    1.96058820e-15   6.12395412e-19]\n",
      " [  1.12085150e-33   8.31448917e-16   5.02127931e-02   9.49787199e-01\n",
      "    5.89997780e-22   2.47564612e-31   9.20317658e-35   1.17902036e-16\n",
      "    2.97956379e-17   8.44918617e-14]\n",
      " [  1.86344856e-30   1.53925739e-17   1.00000000e+00   7.95253099e-11\n",
      "    1.28177844e-31   3.76739284e-27   4.67224739e-32   1.49036477e-23\n",
      "    1.44026306e-12   8.71107145e-11]\n",
      " [  1.44156644e-22   4.32697385e-11   9.99995947e-01   4.10553048e-06\n",
      "    7.51168008e-17   2.56989885e-30   1.26803625e-28   1.53035229e-09\n",
      "    1.09803043e-13   3.11387641e-14]\n",
      " [  6.61605770e-11   5.12840813e-07   9.97744083e-01   4.28754667e-08\n",
      "    6.12540809e-17   5.37824262e-22   4.30620554e-28   1.87398101e-11\n",
      "    2.25532847e-03   7.05212366e-19]\n",
      " [  0.00000000e+00   7.60883493e-18   3.11877858e-03   8.82156056e-13\n",
      "    1.00623642e-23   4.51417820e-10   4.03054767e-28   9.82541144e-01\n",
      "    8.99172026e-14   1.43401157e-02]\n",
      " [  1.16211675e-06   5.75060615e-13   9.82911468e-01   1.70871429e-02\n",
      "    1.39551565e-11   1.93421668e-12   1.93387858e-18   7.19072046e-09\n",
      "    2.80617684e-07   1.13153966e-08]\n",
      " [  3.95835056e-26   1.22253966e-20   6.59278110e-02   2.45926919e-14\n",
      "    9.06888795e-17   5.62976315e-14   8.70203158e-30   6.49563862e-27\n",
      "    9.34072196e-01   5.35309969e-13]\n",
      " [  1.42522797e-25   2.39282763e-15   1.67381131e-08   8.63005547e-24\n",
      "    7.20578289e-25   1.17580281e-21   4.55063941e-37   9.97585535e-01\n",
      "    2.41446309e-03   9.35163346e-30]\n",
      " [  9.59120075e-11   4.09940594e-22   8.09421280e-11   8.42009840e-08\n",
      "    8.16295948e-03   3.86776982e-17   5.43754438e-23   9.91834641e-01\n",
      "    2.24165706e-06   5.80798581e-16]\n",
      " [  1.91393275e-16   3.09029382e-25   9.65454601e-05   5.04352613e-07\n",
      "    1.69873199e-16   9.99902964e-01   5.78263663e-27   3.03312402e-14\n",
      "    8.45394664e-13   1.30599047e-16]\n",
      " [  2.32964633e-16   2.30542134e-25   8.65070164e-01   9.70860059e-16\n",
      "    1.92860007e-22   1.34928629e-01   2.19754731e-20   2.18525980e-08\n",
      "    1.14592217e-06   1.16295623e-15]\n",
      " [  7.05776400e-31   1.17723944e-19   9.04666722e-01   2.74818335e-02\n",
      "    1.25255101e-11   6.17628004e-10   2.80349261e-21   8.18052914e-09\n",
      "    6.78507760e-02   7.10055190e-07]\n",
      " [  8.95452068e-19   4.00539962e-10   1.02766611e-13   4.32037288e-11\n",
      "    7.57358876e-18   4.41919721e-13   4.50761900e-18   8.39138394e-08\n",
      "    9.99995112e-01   4.78196944e-06]\n",
      " [  3.63187897e-28   9.33153406e-28   1.79106263e-12   2.10264943e-08\n",
      "    6.96990462e-21   6.79885078e-19   2.35873298e-21   1.32138929e-13\n",
      "    1.00000000e+00   1.75051461e-15]\n",
      " [  0.00000000e+00   4.54973033e-15   9.99999881e-01   1.69051459e-13\n",
      "    1.02910475e-17   1.30491768e-15   8.01809471e-27   2.07929923e-11\n",
      "    8.78747317e-17   7.22741902e-08]\n",
      " [  4.94271000e-26   7.26193872e-15   9.99999881e-01   2.46811277e-15\n",
      "    7.80184944e-12   2.61667476e-34   4.02796962e-27   1.82974746e-25\n",
      "    7.49481401e-08   1.13821331e-29]\n",
      " [  1.76258391e-17   3.30614054e-34   1.16341154e-13   1.07535134e-18\n",
      "    4.19786861e-28   1.27134370e-33   0.00000000e+00   9.97856438e-01\n",
      "    2.14359001e-03   2.39047173e-18]\n",
      " [  2.60117031e-05   4.44773479e-29   9.37455552e-05   3.33157900e-15\n",
      "    3.87907718e-19   7.83244894e-28   5.86635268e-33   4.32060668e-21\n",
      "    8.67902301e-03   9.91201162e-01]\n",
      " [  6.62813662e-13   1.59460195e-20   2.28090315e-07   5.60521041e-20\n",
      "    2.30348831e-15   3.00087103e-20   5.24209913e-20   9.62658578e-06\n",
      "    9.99990106e-01   1.05321817e-16]\n",
      " [  9.57044231e-13   2.29288431e-16   1.00000000e+00   5.02698493e-19\n",
      "    2.75396848e-29   1.51348884e-22   5.92393305e-35   8.23604944e-37\n",
      "    1.13239284e-14   1.35051737e-22]\n",
      " [  1.76761014e-33   5.30589110e-19   9.99870658e-01   1.76591755e-08\n",
      "    3.56132912e-16   7.56028540e-20   1.76177615e-23   1.29705122e-05\n",
      "    1.16292038e-04   3.84320130e-16]\n",
      " [  2.38819382e-28   8.74242330e-19   6.42255304e-10   4.27421219e-06\n",
      "    2.26321866e-21   1.02470827e-11   1.53814443e-28   9.63360727e-01\n",
      "    3.66350487e-02   1.68899703e-08]\n",
      " [  5.48273605e-32   4.71601452e-05   9.99952674e-01   2.87718773e-25\n",
      "    5.55899002e-26   4.35378660e-28   0.00000000e+00   1.18479711e-07\n",
      "    1.83847620e-14   9.35894169e-19]\n",
      " [  6.06628864e-20   8.10634459e-12   3.21003987e-04   7.39344898e-07\n",
      "    1.16573189e-18   2.38878517e-22   1.58027193e-35   3.36679955e-11\n",
      "    1.51264845e-04   9.99526978e-01]\n",
      " [  1.42846250e-17   1.28053348e-14   1.09703435e-09   6.09470084e-02\n",
      "    4.45285675e-18   3.19008305e-16   1.97301680e-37   3.45425244e-09\n",
      "    9.39052939e-01   8.46957574e-11]\n",
      " [  1.38037783e-17   8.00600450e-26   9.99989629e-01   1.09494732e-24\n",
      "    6.32151398e-08   9.49164778e-24   1.34208527e-23   1.02989970e-05\n",
      "    4.09451500e-11   1.30329136e-09]\n",
      " [  8.69067649e-17   4.09170991e-16   8.09241179e-03   1.80637318e-08\n",
      "    1.36053308e-10   5.47527520e-07   3.24955550e-14   9.28821246e-05\n",
      "    3.39231810e-05   9.91780221e-01]\n",
      " [  1.14329248e-30   1.29102437e-17   2.04285097e-05   9.36444402e-01\n",
      "    1.34327158e-26   1.14113963e-08   5.20568256e-30   6.34974986e-02\n",
      "    2.52214650e-05   1.25252436e-05]\n",
      " [  0.00000000e+00   3.64676625e-33   1.00000000e+00   2.70084356e-31\n",
      "    1.28842762e-36   1.42340484e-27   0.00000000e+00   1.59056933e-38\n",
      "    8.00108645e-17   0.00000000e+00]\n",
      " [  4.68406875e-22   1.05327372e-15   1.19136192e-03   6.32094765e-10\n",
      "    4.42554060e-23   1.65541205e-05   6.70203653e-25   9.97809231e-01\n",
      "    9.82871279e-04   5.21561532e-08]\n",
      " [  6.72285792e-22   8.54823497e-07   3.57476565e-05   1.28272281e-03\n",
      "    9.46499800e-21   3.88541849e-07   4.61554841e-28   3.31423985e-11\n",
      "    9.98680294e-01   4.77052772e-12]\n",
      " [  2.05979700e-36   2.94517776e-16   1.00000000e+00   1.03776089e-19\n",
      "    4.89330387e-30   1.28114980e-13   7.37743162e-28   2.76116991e-17\n",
      "    8.36114746e-16   6.86671275e-11]\n",
      " [  3.26116784e-17   9.47278979e-16   1.67306962e-06   9.99995589e-01\n",
      "    1.37322684e-14   2.22392573e-11   1.07325019e-26   2.70648138e-06\n",
      "    1.68295187e-11   1.67308498e-18]\n",
      " [  1.30902023e-07   1.00701890e-13   9.99871373e-01   6.03148087e-11\n",
      "    6.45940454e-05   6.39325579e-17   1.80760897e-13   4.78229194e-05\n",
      "    1.92726063e-07   1.58690982e-05]\n",
      " [  7.51168572e-11   1.87147126e-20   4.81502704e-09   1.26324368e-10\n",
      "    2.99315919e-20   5.40500405e-05   7.13383820e-14   1.31320328e-01\n",
      "    1.48789769e-09   8.68625641e-01]\n",
      " [  3.38654489e-19   1.44766412e-11   9.99994159e-01   3.95162542e-10\n",
      "    1.00866259e-18   1.01023693e-06   1.73426355e-26   5.85335681e-15\n",
      "    6.08854078e-10   4.86258568e-06]\n",
      " [  1.13187468e-13   2.95381631e-17   9.55335796e-02   1.07912593e-17\n",
      "    9.04058695e-01   1.52962272e-07   1.60217472e-24   7.05335523e-09\n",
      "    3.69089015e-04   3.85196399e-05]\n",
      " [  6.73954027e-29   7.80899928e-11   9.99982715e-01   2.13545737e-10\n",
      "    5.04023765e-21   1.31896002e-12   1.39200506e-27   8.05957315e-11\n",
      "    1.73066055e-05   3.50872242e-09]\n",
      " [  2.32367531e-26   1.44679977e-17   2.96236885e-05   7.72647438e-21\n",
      "    1.74479118e-28   1.06478180e-26   6.94785464e-35   5.34550406e-21\n",
      "    9.51433936e-24   9.99970317e-01]\n",
      " [  1.18347567e-27   3.84580958e-18   9.31782971e-13   9.98430431e-01\n",
      "    1.05924457e-32   3.15276215e-21   2.61499666e-22   2.77138955e-04\n",
      "    1.29247212e-03   8.31507003e-15]\n",
      " [  5.82978631e-12   7.99500327e-11   9.99793351e-01   1.66554351e-20\n",
      "    1.33311027e-04   5.21956645e-10   2.14815122e-19   1.64335205e-07\n",
      "    5.54841899e-05   1.77361126e-05]\n",
      " [  6.51388660e-33   6.67176559e-04   1.25822083e-07   1.64864434e-06\n",
      "    6.96353261e-31   8.12966621e-12   3.66803588e-26   1.03308494e-07\n",
      "    3.21296809e-14   9.99330997e-01]\n",
      " [  8.23534483e-18   1.17900174e-06   9.99996424e-01   6.88638213e-09\n",
      "    2.85642908e-30   9.76833289e-20   1.17591671e-31   2.35229072e-06\n",
      "    9.91603952e-11   4.24951914e-12]\n",
      " [  1.02596252e-22   5.77297377e-11   1.00000000e+00   5.68433071e-14\n",
      "    1.27342863e-18   1.03454370e-26   8.31960906e-28   9.65396586e-14\n",
      "    5.51957147e-10   7.33682104e-13]]\n",
      "INFO:tensorflow:probabilites = [[  5.24899997e-02   1.41546512e-02   9.33725154e-04   8.95534933e-04\n",
      "    9.46855452e-03   7.01376330e-03   8.94717216e-01   7.04544291e-05\n",
      "    1.64904706e-02   3.76571994e-03]\n",
      " [  3.44085856e-04   1.23129564e-03   2.17500282e-03   1.97600093e-04\n",
      "    1.53259211e-03   7.13484548e-03   2.47417786e-03   1.20556200e-04\n",
      "    9.84174550e-01   6.15215511e-04]\n",
      " [  7.73587346e-01   2.91734759e-04   2.11114720e-01   5.54675134e-05\n",
      "    2.01521601e-04   7.29377288e-03   1.39845640e-03   3.42912099e-05\n",
      "    5.52200852e-03   5.00755152e-04]\n",
      " [  4.43365570e-04   1.95093016e-05   1.86845532e-03   5.55444567e-05\n",
      "    6.14931285e-02   3.53172212e-03   6.33014133e-04   1.13561609e-05\n",
      "    3.89173767e-03   9.28052187e-01]\n",
      " [  2.65626963e-02   5.47678806e-02   4.47787228e-04   1.72846741e-03\n",
      "    5.58374822e-03   7.95910091e-05   1.85350844e-04   8.48826312e-04\n",
      "    3.09571207e-01   6.00224495e-01]\n",
      " [  7.07490146e-01   1.13431073e-03   1.38303554e-02   6.04089955e-03\n",
      "    9.96417715e-04   3.64165418e-02   8.30424428e-02   8.25613170e-05\n",
      "    1.48477957e-01   2.48835678e-03]\n",
      " [  1.97085575e-03   6.58155322e-01   1.64150749e-03   1.42547302e-02\n",
      "    6.71238033e-03   2.96840191e-01   2.84955301e-03   1.00890053e-02\n",
      "    6.15868345e-03   1.32777239e-03]\n",
      " [  1.72000576e-03   2.96126973e-06   4.09411819e-04   7.50943832e-03\n",
      "    2.12905817e-07   9.84360635e-01   3.74814350e-04   5.02382824e-03\n",
      "    5.85805567e-04   1.29362561e-05]\n",
      " [  2.51593411e-01   4.02214751e-03   9.74771827e-02   3.84222120e-01\n",
      "    2.98719686e-02   3.38674001e-02   9.04721266e-04   6.34526834e-02\n",
      "    2.29364075e-03   1.32294700e-01]\n",
      " [  2.47709500e-03   5.24056552e-04   1.60520691e-02   1.48796797e-04\n",
      "    7.32350886e-01   2.41381880e-02   1.79013893e-01   3.93576920e-05\n",
      "    3.75190750e-02   7.73656135e-03]\n",
      " [  1.05677079e-03   1.39728814e-04   3.13952123e-03   7.59917140e-01\n",
      "    3.59123573e-04   1.92363024e-01   4.49094409e-03   1.62353122e-03\n",
      "    3.67374308e-02   1.72851025e-04]\n",
      " [  3.36724224e-05   2.03981384e-04   2.71005283e-05   1.20116433e-03\n",
      "    1.18605954e-06   4.00895306e-06   1.33169885e-06   9.93170857e-01\n",
      "    1.24371378e-04   5.23232203e-03]\n",
      " [  1.25427879e-02   1.51747954e-04   6.05912328e-01   1.59914181e-01\n",
      "    7.27904378e-04   1.67171918e-02   1.32681215e-02   6.68432284e-03\n",
      "    1.83284387e-01   7.97018933e-04]\n",
      " [  1.57077201e-02   1.40206394e-04   8.77457860e-05   3.30052413e-02\n",
      "    2.45130667e-03   8.96245122e-01   1.87672116e-03   1.40549120e-04\n",
      "    5.00170253e-02   3.28353926e-04]\n",
      " [  1.94957107e-03   1.95309147e-01   1.77391451e-02   3.98435704e-02\n",
      "    4.02306974e-01   2.78442681e-01   7.30850035e-03   2.67037619e-02\n",
      "    1.78690720e-02   1.25275757e-02]\n",
      " [  9.80872777e-04   3.98950040e-01   5.85197628e-01   7.48412684e-04\n",
      "    2.46260292e-03   2.01043251e-04   5.37548587e-03   1.18480413e-04\n",
      "    1.02903415e-03   4.93639475e-03]\n",
      " [  9.53841329e-01   5.30156431e-05   1.44505480e-04   3.23379936e-04\n",
      "    5.23676223e-04   1.83885757e-04   4.46171127e-02   1.37437121e-06\n",
      "    2.31870639e-04   7.98704277e-05]\n",
      " [  2.28428798e-05   2.51187453e-06   1.26806844e-04   1.48527815e-05\n",
      "    8.36294839e-06   2.92588578e-04   4.59133844e-07   9.92349923e-01\n",
      "    1.36079767e-03   5.82063943e-03]\n",
      " [  3.98538308e-03   9.49484348e-01   7.98257883e-04   5.14662708e-04\n",
      "    5.28842444e-04   6.93789159e-04   9.35808849e-03   1.07790772e-02\n",
      "    2.31218524e-02   7.35635520e-04]\n",
      " [  3.70889524e-04   8.90402377e-01   1.28693192e-03   8.13328773e-02\n",
      "    2.88184558e-04   3.80567298e-03   3.68999375e-04   3.64598865e-03\n",
      "    1.89230253e-03   1.66057572e-02]\n",
      " [  1.77190341e-02   1.18008986e-01   1.37713626e-01   1.68282501e-02\n",
      "    3.81554361e-03   1.54463065e-04   8.37212647e-05   6.64866686e-01\n",
      "    3.87728075e-03   3.69323529e-02]\n",
      " [  4.33503538e-02   5.14281914e-03   3.12074989e-01   2.98489613e-04\n",
      "    3.82184088e-01   6.16722647e-03   3.23381711e-04   1.02974991e-04\n",
      "    6.64844224e-03   2.43707299e-01]\n",
      " [  2.56118514e-02   1.77894738e-02   6.96778204e-03   9.96152125e-03\n",
      "    1.44498602e-01   2.15050206e-01   3.00518990e-01   2.40369871e-01\n",
      "    3.75956967e-02   1.63599744e-03]\n",
      " [  1.57119604e-04   4.72905922e-05   1.17547374e-04   5.03076240e-04\n",
      "    3.10822222e-02   2.71675439e-04   6.36401493e-03   1.18064126e-02\n",
      "    9.82657634e-03   9.39824104e-01]\n",
      " [  8.33892286e-01   7.30749918e-03   2.52188258e-02   5.41899540e-03\n",
      "    8.73195529e-02   8.13846756e-03   2.78715417e-03   5.60095708e-04\n",
      "    1.57342907e-02   1.36229359e-02]\n",
      " [  9.32440162e-06   1.18855394e-04   9.96377289e-01   1.27223821e-03\n",
      "    3.57129065e-05   1.03919534e-04   2.04961142e-03   3.73654075e-06\n",
      "    3.41349505e-06   2.59798835e-05]\n",
      " [  2.94747148e-02   5.44171280e-06   9.68340158e-01   1.19088327e-04\n",
      "    1.40329439e-03   1.39749289e-04   3.95524125e-07   1.02597669e-05\n",
      "    3.48217814e-04   1.58734081e-04]\n",
      " [  3.33558601e-05   4.35664560e-06   2.65854214e-05   4.15725983e-04\n",
      "    1.67814913e-04   3.54482063e-06   4.10470165e-08   9.98582959e-01\n",
      "    5.04429727e-06   7.60594790e-04]\n",
      " [  4.30301843e-05   1.41487315e-01   1.14831992e-03   9.68607259e-04\n",
      "    8.47915709e-01   6.41644292e-04   1.95229550e-05   2.93820922e-04\n",
      "    2.68087984e-04   7.21389102e-03]\n",
      " [  9.92248416e-01   1.52582608e-04   2.72583886e-04   3.79979541e-03\n",
      "    8.32280602e-06   1.26004801e-03   2.62630812e-04   4.49087065e-06\n",
      "    1.98427611e-03   6.84956285e-06]\n",
      " [  2.40392867e-03   9.47361469e-01   3.38213034e-02   8.16182073e-05\n",
      "    3.13200150e-03   1.76557142e-03   9.09136957e-04   6.04988588e-03\n",
      "    4.29299474e-03   1.82014235e-04]\n",
      " [  5.51351486e-03   6.65144343e-03   5.86844562e-03   6.61900759e-01\n",
      "    1.51099592e-01   1.55100793e-01   1.74468197e-03   5.57384221e-04\n",
      "    6.48201734e-04   1.09152030e-02]\n",
      " [  1.37874847e-02   8.88023787e-05   1.55138713e-03   9.34416585e-06\n",
      "    1.07195199e-01   5.01924008e-03   7.31752813e-03   2.23356835e-03\n",
      "    8.82927561e-05   8.62709105e-01]\n",
      " [  1.95237380e-02   8.15226287e-02   4.91515189e-01   1.16231171e-02\n",
      "    2.92106599e-01   7.52391899e-03   2.11143564e-03   1.24822836e-04\n",
      "    9.38439369e-02   1.04581020e-04]\n",
      " [  4.59317744e-06   2.00763205e-03   2.34469171e-05   2.67035095e-03\n",
      "    1.33828080e-05   1.02362130e-04   2.34012568e-05   9.16872025e-01\n",
      "    2.23424286e-02   5.59403673e-02]\n",
      " [  2.72445730e-04   4.81854111e-01   1.40408352e-02   1.28322968e-03\n",
      "    3.08032721e-01   3.44024203e-03   1.76118119e-04   1.48554886e-04\n",
      "    1.85995817e-01   4.75593517e-03]\n",
      " [  1.14075316e-03   9.27628353e-05   6.90047503e-01   1.26226954e-02\n",
      "    2.64501780e-01   1.46444216e-02   4.75278730e-03   4.77080874e-04\n",
      "    1.02134480e-03   1.06987851e-02]\n",
      " [  2.36487035e-02   3.18411877e-03   6.00811443e-04   1.65237579e-02\n",
      "    1.20284576e-02   3.90885725e-05   6.31980656e-04   1.95014533e-02\n",
      "    2.41501932e-03   9.21426594e-01]\n",
      " [  3.54151649e-04   6.61477679e-04   7.52647931e-04   6.47280514e-02\n",
      "    1.90314173e-03   9.09572303e-01   1.46612339e-03   4.37909621e-05\n",
      "    2.04298962e-02   8.83424000e-05]\n",
      " [  6.93282404e-04   2.84779981e-06   1.51250430e-03   2.26421515e-04\n",
      "    1.44642331e-02   9.45370734e-01   1.22257348e-04   1.04692357e-03\n",
      "    3.65551300e-02   5.68442420e-06]\n",
      " [  1.30507080e-02   3.01303435e-02   2.82384735e-02   3.16676288e-03\n",
      "    4.80365427e-03   8.82302132e-03   3.92560631e-01   1.51498534e-04\n",
      "    8.02598521e-03   5.11048973e-01]\n",
      " [  8.46507737e-06   1.99207648e-06   4.91106730e-05   3.31840897e-03\n",
      "    1.31097739e-04   2.34980645e-04   2.28609409e-07   9.88804281e-01\n",
      "    3.70675007e-05   7.41433119e-03]\n",
      " [  6.90635134e-05   7.37916399e-03   4.01404861e-04   5.17200911e-04\n",
      "    7.35325992e-01   3.28800874e-04   1.16873365e-02   1.27226496e-02\n",
      "    3.86620276e-02   1.92906275e-01]\n",
      " [  8.47871676e-02   3.77198012e-04   7.11931065e-02   1.56988855e-02\n",
      "    4.66019753e-03   1.79098838e-03   8.01873446e-01   2.06063851e-03\n",
      "    9.54806712e-03   8.01031478e-03]\n",
      " [  3.82145008e-05   6.16005400e-06   6.03770013e-06   9.88516569e-01\n",
      "    5.33054845e-06   1.08531890e-02   5.20584057e-04   1.04248443e-06\n",
      "    6.92232334e-06   4.59979092e-05]\n",
      " [  2.01307461e-02   1.86642911e-03   4.25380059e-02   2.21812986e-02\n",
      "    9.42662507e-02   3.66367400e-02   7.74198651e-01   9.95876035e-04\n",
      "    6.89140614e-03   2.94603669e-04]\n",
      " [  2.68700451e-01   2.92801820e-02   5.30232549e-01   1.33729763e-02\n",
      "    1.23119704e-01   4.57708631e-03   2.82136071e-02   6.34440585e-05\n",
      "    1.29713223e-03   1.14290661e-03]\n",
      " [  3.43324721e-01   9.95699898e-04   1.60828289e-02   3.89957607e-01\n",
      "    1.73393469e-02   5.40919183e-03   3.42049333e-03   3.12290504e-04\n",
      "    2.17696935e-01   5.46090491e-03]\n",
      " [  1.52009930e-02   1.07064540e-03   4.62337583e-03   1.25335017e-03\n",
      "    2.95911487e-02   1.24225244e-02   8.54472280e-01   5.31902350e-02\n",
      "    2.47318894e-02   3.44358059e-03]\n",
      " [  9.93881583e-01   3.64082589e-05   9.63332830e-04   1.74773068e-05\n",
      "    3.59592887e-05   9.42174665e-06   4.08524647e-03   2.00650029e-05\n",
      "    8.41409375e-04   1.09057044e-04]\n",
      " [  1.12620783e-05   8.76439299e-06   6.72541064e-05   1.44673811e-06\n",
      "    3.45129524e-06   6.77708840e-06   1.38925197e-05   9.99454916e-01\n",
      "    3.98037839e-04   3.42365820e-05]\n",
      " [  8.66486192e-01   2.54362996e-04   4.03430266e-03   1.40470592e-02\n",
      "    1.30845541e-02   9.23053361e-03   9.79496865e-04   7.02291308e-03\n",
      "    8.48265365e-02   3.41092637e-05]\n",
      " [  1.93583164e-02   9.87498984e-02   3.87236148e-01   4.45017159e-01\n",
      "    7.93565239e-04   7.60551915e-03   1.31833029e-03   9.27644796e-05\n",
      "    3.22987027e-02   7.52956094e-03]\n",
      " [  6.10183088e-05   6.89925457e-07   1.74788292e-03   1.73856750e-01\n",
      "    7.66919184e-05   8.17420602e-01   5.82224084e-03   6.70630659e-04\n",
      "    3.30616283e-04   1.29072987e-05]\n",
      " [  9.03049767e-01   4.10178727e-05   6.62999526e-02   4.66103572e-03\n",
      "    1.52169187e-02   1.12322916e-03   1.90815146e-04   9.55378200e-05\n",
      "    9.29563772e-03   2.60333400e-05]\n",
      " [  5.11061691e-04   4.12085699e-03   2.31425138e-03   7.02999383e-02\n",
      "    2.02608513e-04   1.76673129e-01   1.53627899e-02   9.20765044e-04\n",
      "    7.29499221e-01   9.52839182e-05]\n",
      " [  7.68221200e-01   6.75561198e-04   1.79597680e-02   5.57129970e-03\n",
      "    1.23891093e-01   5.08538540e-03   6.91674873e-02   2.20531761e-03\n",
      "    5.40391193e-04   6.68240758e-03]\n",
      " [  2.91846693e-03   1.48359016e-01   4.87288572e-02   2.08673552e-01\n",
      "    4.80274763e-03   7.47658387e-02   3.71329021e-04   6.03830849e-04\n",
      "    5.10173738e-01   6.02678221e-04]\n",
      " [  2.78234831e-04   1.97488852e-02   1.36265811e-02   1.28181027e-02\n",
      "    3.47282505e-03   1.46714017e-01   7.96905041e-01   1.38426386e-03\n",
      "    4.26404038e-03   7.88052392e-04]\n",
      " [  6.55341682e-06   9.95335996e-01   5.71416313e-05   2.48000899e-04\n",
      "    6.58237695e-05   5.34346676e-04   9.12661490e-04   1.74460962e-04\n",
      "    1.84832461e-04   2.48041563e-03]\n",
      " [  3.74804497e-01   5.53056523e-02   4.65845019e-01   2.67535727e-03\n",
      "    6.97928993e-03   6.21123388e-02   4.33917623e-03   1.38544114e-04\n",
      "    2.72924192e-02   5.07812016e-04]\n",
      " [  4.07745072e-04   6.79083041e-06   7.00051114e-02   4.44220565e-03\n",
      "    6.95134368e-05   1.80568695e-05   9.24891412e-01   3.79472539e-07\n",
      "    1.50569293e-04   8.22849597e-06]\n",
      " [  1.35987031e-03   2.52290425e-04   5.90162119e-03   1.07371445e-04\n",
      "    3.66668284e-01   1.27238175e-03   1.46888895e-04   4.75238124e-03\n",
      "    1.55838241e-03   6.17980540e-01]\n",
      " [  2.19673548e-05   1.11847499e-03   1.86492853e-05   4.35275678e-03\n",
      "    2.61670037e-04   1.11659663e-02   9.53141749e-01   1.52214023e-03\n",
      "    2.77625788e-02   6.34190976e-04]\n",
      " [  2.54207361e-03   6.32683395e-06   5.59996151e-05   1.19632577e-05\n",
      "    6.21655083e-04   1.88650447e-04   8.84391702e-05   3.56371522e-01\n",
      "    2.95801496e-04   6.39817595e-01]\n",
      " [  2.76259077e-03   2.17362982e-03   5.12066111e-03   8.94146144e-01\n",
      "    6.22835308e-02   3.10444236e-02   1.35250890e-03   9.89891778e-05\n",
      "    5.64683171e-04   4.52804787e-04]\n",
      " [  1.27236242e-03   1.95867178e-04   1.69451516e-02   3.29264015e-01\n",
      "    3.15250145e-05   6.45496309e-01   6.44363044e-03   1.22601065e-04\n",
      "    2.13299267e-04   1.52242055e-05]\n",
      " [  2.81199790e-03   9.44295079e-02   1.10686861e-03   6.60919031e-05\n",
      "    1.47615010e-02   8.84113252e-01   8.99443228e-04   4.59920237e-04\n",
      "    1.24197526e-04   1.22728397e-03]\n",
      " [  3.16479034e-03   1.33295143e-02   1.78464223e-04   2.15992593e-04\n",
      "    2.85974778e-02   1.03402389e-02   5.00565919e-04   3.78137887e-01\n",
      "    6.38518902e-03   5.59149861e-01]\n",
      " [  9.94677067e-01   2.60052843e-06   1.42579709e-04   7.56111986e-04\n",
      "    2.27313256e-04   9.63996281e-04   3.03974468e-03   5.35543513e-05\n",
      "    1.17266769e-04   1.98487960e-05]\n",
      " [  9.88164663e-01   4.22888297e-06   7.39903422e-04   9.25871264e-03\n",
      "    7.03277965e-06   7.98157416e-04   9.82094090e-04   7.56412783e-06\n",
      "    3.57572208e-05   1.78818323e-06]\n",
      " [  1.08702364e-03   3.48595274e-03   2.66049810e-05   7.19170785e-05\n",
      "    1.30569295e-03   2.30042590e-03   7.79419532e-03   1.39465228e-05\n",
      "    9.83325720e-01   5.88541850e-04]\n",
      " [  1.25957523e-02   2.45126360e-03   6.70555339e-04   6.49681166e-02\n",
      "    2.60374369e-03   8.87336552e-01   9.34340496e-05   5.44628873e-03\n",
      "    2.25727651e-02   1.26159005e-03]\n",
      " [  4.35189269e-02   1.14037961e-01   3.74854133e-02   1.90150291e-02\n",
      "    1.91106182e-02   1.01873223e-02   6.74269140e-01   4.88291774e-03\n",
      "    7.65974522e-02   8.95233534e-04]\n",
      " [  5.67850145e-03   4.72214445e-03   9.85026419e-01   2.24911771e-03\n",
      "    3.35865093e-06   4.11992369e-04   1.12167711e-03   8.07422566e-07\n",
      "    4.56305221e-04   3.29762406e-04]\n",
      " [  1.01659708e-02   2.40970083e-04   9.41223577e-02   8.94128680e-01\n",
      "    4.97366884e-04   9.33467454e-05   2.77394283e-04   1.04274841e-04\n",
      "    3.01482476e-04   6.81722522e-05]\n",
      " [  5.15724957e-01   1.07428357e-01   1.16999023e-01   1.48533806e-01\n",
      "    2.72573112e-03   5.50117642e-02   4.32834681e-03   3.49567309e-02\n",
      "    8.59576836e-03   5.69549808e-03]\n",
      " [  2.08731950e-03   7.17188464e-03   2.39942878e-01   1.02239167e-02\n",
      "    1.00488123e-03   1.60487313e-02   1.08527788e-03   1.42408671e-05\n",
      "    7.21314013e-01   1.10682717e-03]\n",
      " [  2.81243178e-04   3.73967545e-04   1.43868150e-04   3.80994612e-03\n",
      "    9.15775120e-01   5.50843019e-04   1.08136401e-05   1.32345001e-03\n",
      "    2.46683630e-04   7.74840340e-02]\n",
      " [  4.05270039e-05   8.59080911e-01   1.94315147e-02   1.32264812e-02\n",
      "    7.22968252e-05   3.50299262e-04   3.61383101e-03   1.52900279e-03\n",
      "    3.15541215e-02   7.11009353e-02]\n",
      " [  8.40898952e-04   1.69637725e-01   1.75690220e-04   3.63148330e-03\n",
      "    1.45941079e-02   6.91389723e-04   2.25997902e-03   1.36523411e-01\n",
      "    6.37198746e-01   3.44465636e-02]\n",
      " [  6.67859837e-02   1.05942111e-03   9.31231916e-01   5.44537670e-06\n",
      "    2.92723980e-05   1.97992835e-04   2.29200214e-06   4.11947520e-04\n",
      "    2.75530707e-04   1.50439163e-07]\n",
      " [  2.37527934e-06   1.25512088e-06   1.15499479e-05   9.96860743e-01\n",
      "    1.24007775e-05   2.46151816e-03   1.38310279e-04   6.05783753e-05\n",
      "    1.83083393e-04   2.68279779e-04]\n",
      " [  1.94254190e-01   2.60344696e-05   5.34928543e-03   4.01278678e-03\n",
      "    8.76488090e-02   3.17176968e-01   3.46384384e-03   3.35469581e-02\n",
      "    3.53328735e-01   1.19240198e-03]\n",
      " [  3.25774476e-02   2.36411132e-02   4.16511208e-01   3.52640063e-01\n",
      "    9.33846983e-04   1.99049953e-02   2.50396249e-03   3.98488855e-03\n",
      "    1.45659700e-01   1.64277537e-03]\n",
      " [  9.49425280e-01   5.58876934e-07   4.57097340e-04   9.43982814e-05\n",
      "    4.37796225e-05   4.22376543e-02   4.40161768e-03   1.86648431e-05\n",
      "    3.15669947e-03   1.64290817e-04]\n",
      " [  4.42936958e-04   4.90774721e-01   1.63726415e-02   6.22013025e-02\n",
      "    2.56032944e-01   4.62216288e-02   2.47570276e-02   9.61737558e-02\n",
      "    3.21889226e-03   3.80416540e-03]\n",
      " [  2.55205698e-04   1.33096322e-01   6.59079611e-01   1.99724687e-04\n",
      "    2.72009410e-02   1.28808459e-02   1.88639257e-02   9.59675163e-02\n",
      "    4.62202244e-02   6.23565586e-03]\n",
      " [  1.02725207e-04   7.62442453e-03   4.19210821e-01   2.31775958e-02\n",
      "    1.22468825e-02   1.75102018e-02   1.08574316e-01   6.90972293e-03\n",
      "    1.29213473e-02   3.91721934e-01]\n",
      " [  2.46061847e-01   2.04896387e-05   1.19809397e-02   3.08048371e-02\n",
      "    2.22786376e-03   5.85294468e-03   1.48700058e-01   1.28895580e-03\n",
      "    5.52140892e-01   9.21218132e-04]\n",
      " [  3.67201719e-05   1.77905150e-03   1.67247057e-02   7.89392088e-03\n",
      "    8.92054010e-03   5.60426526e-03   2.93183723e-04   3.13431710e-01\n",
      "    1.03686831e-03   6.44279122e-01]\n",
      " [  4.24417295e-03   3.53830338e-01   4.40125056e-02   4.19812687e-02\n",
      "    2.39964621e-03   2.51156831e-04   6.71969377e-04   2.49892846e-03\n",
      "    5.48819542e-01   1.29045115e-03]\n",
      " [  3.13591771e-02   8.58969510e-01   5.60595887e-03   4.43063723e-03\n",
      "    1.19666122e-02   9.51078627e-03   3.91152948e-02   1.54487439e-04\n",
      "    3.71323600e-02   1.75521022e-03]\n",
      " [  5.10728714e-05   9.38897491e-01   3.28280905e-04   9.82033787e-04\n",
      "    8.75739643e-05   2.27104011e-03   5.26015908e-02   1.74038683e-03\n",
      "    2.19305535e-03   8.47399642e-04]\n",
      " [  1.52414184e-04   2.32648384e-03   3.28053320e-05   2.31486920e-05\n",
      "    1.68328006e-06   1.67930139e-05   1.20652942e-06   9.95238423e-01\n",
      "    6.01957028e-04   1.60499674e-03]\n",
      " [  1.48036388e-05   1.09377243e-05   7.78251560e-05   2.40070549e-05\n",
      "    5.39706889e-06   4.49812615e-05   9.99610364e-01   9.78372100e-06\n",
      "    1.09057852e-04   9.27969522e-05]\n",
      " [  3.47339928e-01   1.56548508e-02   3.31980079e-01   7.51004592e-02\n",
      "    4.46437742e-04   1.53229594e-01   1.99358794e-03   6.58064382e-04\n",
      "    7.08238706e-02   2.77312822e-03]\n",
      " [  6.04450796e-03   7.88981188e-03   3.11288983e-02   1.36746779e-01\n",
      "    1.95685308e-04   1.60887232e-03   4.80952160e-03   5.78617990e-01\n",
      "    1.98939964e-02   2.13063940e-01]\n",
      " [  2.54425011e-03   2.88281851e-02   6.00067759e-03   2.95784412e-04\n",
      "    4.73818555e-02   3.55728320e-03   1.11529545e-03   7.25926459e-02\n",
      "    3.06658004e-03   8.34617436e-01]\n",
      " [  2.73921469e-04   3.03531342e-05   4.65055811e-04   6.60110454e-05\n",
      "    9.82281327e-01   1.12345340e-04   6.82979822e-04   2.45109492e-04\n",
      "    4.05254803e-04   1.54376477e-02]]\n",
      "INFO:tensorflow:global_step/sec: 1.97303\n",
      "INFO:tensorflow:loss = 0.699177, step = 101\n",
      "INFO:tensorflow:probabilites = [[  6.78819716e-01   4.90185805e-03   4.55588289e-02   2.78051551e-02\n",
      "    2.41635609e-02   9.03448537e-02   8.30395967e-02   2.90003518e-04\n",
      "    2.26012375e-02   2.24751364e-02]\n",
      " [  9.26433786e-05   9.89273489e-01   6.37310659e-05   3.25691211e-03\n",
      "    1.05219660e-03   2.04559008e-04   1.23366219e-04   1.65106816e-04\n",
      "    1.66460813e-03   4.10334673e-03]\n",
      " [  8.30719873e-05   2.29976152e-07   4.51358756e-05   5.80246342e-05\n",
      "    3.68377209e-06   3.54066462e-04   9.99432266e-01   2.72816294e-07\n",
      "    4.99462112e-06   1.82618296e-05]\n",
      " [  3.07529348e-07   9.20662302e-08   1.07229989e-05   1.66445352e-06\n",
      "    8.74268517e-05   1.74333775e-06   5.61391801e-07   9.99582708e-01\n",
      "    3.02367407e-05   2.84635113e-04]\n",
      " [  3.53575248e-04   1.94495133e-05   5.55054545e-02   2.00600494e-02\n",
      "    1.05320819e-01   2.06847471e-04   3.83663028e-05   1.29196465e-01\n",
      "    4.05105500e-04   6.88893855e-01]\n",
      " [  2.59436201e-04   8.12530890e-03   1.14794937e-04   6.50083303e-01\n",
      "    8.40241410e-05   3.14425856e-01   1.07229884e-04   2.77603016e-04\n",
      "    2.42019668e-02   2.32046563e-03]\n",
      " [  2.43844435e-01   1.62455346e-02   2.09875554e-01   6.70720532e-04\n",
      "    3.23578805e-01   1.73906028e-01   1.68438163e-02   8.59559048e-04\n",
      "    1.29829803e-02   1.19258591e-03]\n",
      " [  4.20919037e-04   4.61577383e-06   1.00056616e-06   2.58752107e-06\n",
      "    1.49221066e-03   7.05633720e-05   6.47477464e-06   4.51537126e-05\n",
      "    3.82831553e-04   9.97573674e-01]\n",
      " [  4.30144655e-06   7.57469563e-04   4.79586306e-05   3.86653119e-03\n",
      "    7.45143407e-05   1.07474756e-04   1.51401955e-05   6.93700058e-05\n",
      "    3.15679424e-03   9.91900563e-01]\n",
      " [  1.45813869e-02   3.08118993e-03   6.17987886e-02   8.06028210e-03\n",
      "    4.64698970e-02   1.18252705e-03   8.60804617e-01   3.59209051e-04\n",
      "    3.31497262e-03   3.47055291e-04]\n",
      " [  7.05302373e-05   1.55661599e-08   3.53100427e-06   1.74388883e-03\n",
      "    1.74120651e-05   9.98161256e-01   2.37946483e-06   3.81753807e-07\n",
      "    3.74926657e-07   1.71315904e-07]\n",
      " [  9.10489082e-01   1.47423343e-04   1.83036237e-03   2.51679169e-03\n",
      "    4.56901835e-05   5.90791286e-04   1.92179233e-02   3.77141623e-05\n",
      "    6.38348013e-02   1.28942821e-03]\n",
      " [  1.37708930e-05   1.43842078e-06   5.22578716e-07   6.05381203e-08\n",
      "    9.99766052e-01   4.05611843e-07   7.95943015e-06   2.05026387e-04\n",
      "    7.78169351e-07   3.95942243e-06]\n",
      " [  1.46865658e-03   5.64329384e-05   2.52609663e-02   8.68520699e-04\n",
      "    8.26632371e-04   4.39556278e-02   4.27420346e-05   9.24814224e-01\n",
      "    8.88609735e-04   1.81757263e-03]\n",
      " [  1.50845435e-05   9.83941734e-01   1.02331303e-03   2.97545013e-03\n",
      "    3.78665957e-03   4.35587310e-04   2.96066911e-03   9.43708656e-05\n",
      "    4.27880930e-03   4.88308258e-04]\n",
      " [  1.42738108e-05   1.28280658e-06   1.00112575e-05   9.99957442e-01\n",
      "    1.71699668e-07   1.07656660e-05   6.35708730e-08   5.02302271e-08\n",
      "    1.03149762e-06   4.95085351e-06]\n",
      " [  9.39214020e-04   1.18562980e-02   4.30421829e-01   1.83833376e-01\n",
      "    1.99117631e-01   4.67956923e-02   6.73824176e-02   5.11057628e-03\n",
      "    5.36756031e-02   8.67378549e-04]\n",
      " [  4.85943019e-06   9.99010801e-01   3.05590984e-05   6.14115265e-07\n",
      "    6.55978394e-04   4.13972157e-06   4.23520578e-06   5.39418943e-05\n",
      "    1.47428364e-04   8.74672915e-05]\n",
      " [  6.27099676e-03   2.32971445e-01   6.86832845e-01   3.01114619e-02\n",
      "    4.48369747e-03   3.53532814e-04   2.02218580e-04   9.09016118e-04\n",
      "    3.37035991e-02   4.16115439e-03]\n",
      " [  2.89351533e-06   4.24165017e-04   9.92760714e-03   9.76104975e-01\n",
      "    4.72221899e-07   1.34207588e-02   4.93321295e-07   1.28451093e-05\n",
      "    7.68972459e-05   2.88916035e-05]\n",
      " [  7.97411427e-03   2.16746796e-02   6.57472154e-03   7.20776439e-01\n",
      "    3.88119882e-03   1.01976171e-02   1.04308929e-05   3.89840011e-03\n",
      "    2.12699950e-01   1.23124225e-02]\n",
      " [  7.94104267e-07   9.94432747e-01   7.21575052e-05   2.61561581e-05\n",
      "    8.87266884e-04   1.68222381e-04   2.19498691e-03   6.63297178e-05\n",
      "    9.10921488e-04   1.24045275e-03]\n",
      " [  1.11675844e-01   3.76636803e-04   6.40977547e-02   7.56644666e-01\n",
      "    1.81690580e-03   4.65786420e-02   4.42828386e-05   8.12973594e-05\n",
      "    4.76255454e-03   1.39213642e-02]\n",
      " [  9.34491456e-02   4.79308050e-03   6.46163942e-04   8.23187875e-04\n",
      "    2.54251808e-01   4.49125730e-02   1.20008946e-04   5.91928244e-01\n",
      "    2.65840744e-03   6.41737133e-03]\n",
      " [  3.33717489e-03   6.98579825e-05   1.76821195e-04   1.10614114e-02\n",
      "    1.29636363e-04   8.99464846e-01   2.82987021e-05   1.28133197e-05\n",
      "    8.57113451e-02   7.75526405e-06]\n",
      " [  1.10914838e-02   3.01678097e-06   9.20008481e-01   6.83926046e-02\n",
      "    6.15451791e-05   1.45860991e-04   2.05791745e-04   4.46472950e-06\n",
      "    8.59252177e-05   8.70898532e-07]\n",
      " [  7.67636404e-04   6.12687320e-04   3.26099270e-03   2.47341348e-04\n",
      "    1.29739556e-03   3.65703902e-03   9.90124822e-01   1.34960018e-07\n",
      "    9.64919764e-06   2.22053368e-05]\n",
      " [  3.69566834e-07   6.36651930e-06   2.52486770e-05   2.59729450e-06\n",
      "    9.99954104e-01   1.70034150e-06   6.06247681e-07   2.79914780e-09\n",
      "    9.66298472e-08   8.99635870e-06]\n",
      " [  1.35746421e-04   9.94701385e-01   2.89514486e-04   4.36156261e-05\n",
      "    3.64904379e-04   1.31918467e-03   8.20172019e-04   6.42445520e-05\n",
      "    2.00791424e-03   2.53320293e-04]\n",
      " [  7.64542213e-03   1.07544497e-01   4.78083014e-01   3.67542773e-01\n",
      "    3.89194628e-03   1.30466244e-03   1.01414660e-03   5.03236835e-04\n",
      "    1.48561010e-02   1.76141020e-02]\n",
      " [  2.95227233e-06   3.72819215e-07   8.08083982e-08   2.42752822e-06\n",
      "    2.72144709e-04   7.72538806e-06   1.23977832e-08   9.99046266e-01\n",
      "    2.50700538e-07   6.67713524e-04]\n",
      " [  9.98016000e-01   3.80431607e-06   9.14640259e-05   1.26915320e-03\n",
      "    1.21712969e-06   2.23060590e-04   1.41379032e-05   1.95108732e-04\n",
      "    1.20241755e-04   6.58646168e-05]\n",
      " [  3.18147749e-01   4.99990210e-03   3.23632509e-02   8.17601802e-04\n",
      "    1.78229865e-02   1.83820985e-02   8.01864713e-02   2.50317037e-01\n",
      "    2.16412470e-01   6.05503954e-02]\n",
      " [  5.67904301e-02   3.56058508e-01   5.03397405e-01   1.95908118e-02\n",
      "    9.94610367e-04   1.29900342e-02   3.18281911e-02   3.56703228e-03\n",
      "    1.21059213e-02   2.67711794e-03]\n",
      " [  2.61874015e-06   9.86780719e-07   3.35502705e-06   4.00281540e-04\n",
      "    1.81389205e-05   2.64394856e-07   1.75402001e-05   9.99194801e-01\n",
      "    3.51578667e-04   1.02362028e-05]\n",
      " [  2.65925890e-04   2.02630889e-02   1.68473704e-03   2.06000707e-03\n",
      "    2.88993143e-03   3.76968249e-03   6.77165296e-03   2.00811155e-05\n",
      "    9.48961616e-01   1.33132031e-02]\n",
      " [  3.57254501e-03   4.04658727e-03   9.55397725e-01   2.28511151e-02\n",
      "    1.98984612e-03   3.55438562e-03   4.97638527e-03   6.97113137e-05\n",
      "    3.52433464e-03   1.73504504e-05]\n",
      " [  2.37434898e-02   2.60886196e-02   1.30392355e-03   9.06954408e-02\n",
      "    6.25092760e-02   2.14332175e-02   1.58944000e-02   9.70117655e-03\n",
      "    3.28792557e-02   7.15751171e-01]\n",
      " [  2.20057147e-04   1.66846985e-05   9.96508896e-01   1.96465477e-03\n",
      "    1.59354977e-06   1.05039275e-03   1.41711894e-06   1.69982275e-04\n",
      "    6.58262725e-05   4.92345521e-07]\n",
      " [  8.27771185e-09   2.89831269e-06   9.99948502e-01   3.91279682e-05\n",
      "    1.89002094e-06   3.14961113e-07   5.74715614e-07   6.39000808e-09\n",
      "    6.13834982e-06   5.01273007e-07]\n",
      " [  1.03350845e-03   8.60301673e-01   2.77721733e-02   1.29260909e-04\n",
      "    1.37542943e-02   4.18229438e-02   9.79654770e-03   1.75884124e-02\n",
      "    2.54627671e-02   2.33836938e-03]\n",
      " [  1.29246313e-04   6.23971719e-05   3.01138552e-05   8.84006295e-05\n",
      "    1.39397584e-04   1.30784302e-03   6.78619642e-07   9.97759581e-01\n",
      "    4.38245304e-04   4.42201126e-05]\n",
      " [  2.50615936e-04   1.35057652e-03   7.13067362e-04   1.30470586e-03\n",
      "    8.62463191e-03   4.50999439e-02   5.23902872e-06   8.41590445e-05\n",
      "    1.30405277e-03   9.41262960e-01]\n",
      " [  9.82527708e-05   2.38196935e-06   3.91743242e-08   4.24158570e-05\n",
      "    1.36652588e-05   3.04770822e-07   5.01987572e-08   9.99632120e-01\n",
      "    1.57117582e-04   5.35164982e-05]\n",
      " [  1.12107480e-02   1.50865875e-02   6.28377966e-05   5.52227430e-05\n",
      "    1.50809786e-03   3.41103226e-03   3.04014772e-01   1.60816577e-04\n",
      "    6.63711488e-01   7.78471061e-04]\n",
      " [  2.19047396e-03   9.77778382e-06   2.15925965e-02   3.63783329e-04\n",
      "    3.96740244e-04   5.38619198e-02   8.49684179e-01   9.87296153e-05\n",
      "    7.16953203e-02   1.06521620e-04]\n",
      " [  5.91878488e-04   5.90783893e-04   8.00799346e-04   1.15236221e-03\n",
      "    5.98471984e-03   1.57497618e-02   9.74907458e-01   1.81018527e-06\n",
      "    7.50926993e-05   1.45352649e-04]\n",
      " [  1.14645548e-01   1.63868850e-03   4.19213669e-04   1.22005390e-02\n",
      "    2.76563525e-01   4.18970681e-04   6.38762285e-05   2.19518971e-03\n",
      "    1.16285449e-03   5.90691566e-01]\n",
      " [  5.30774400e-07   9.94727270e-06   1.25416436e-05   9.99899030e-01\n",
      "    4.13608461e-07   1.28502679e-05   2.76290413e-09   3.14835319e-07\n",
      "    4.48665196e-05   1.94914774e-05]\n",
      " [  7.38611163e-07   1.80304284e-07   6.19831837e-07   3.44205091e-06\n",
      "    3.62362305e-04   2.14269434e-07   1.09266625e-06   3.50380763e-02\n",
      "    3.33340104e-05   9.64559913e-01]\n",
      " [  1.77954793e-01   2.43736450e-02   3.46898556e-01   5.66102425e-03\n",
      "    6.49787625e-03   7.64546031e-03   2.81399977e-03   6.99778646e-03\n",
      "    2.60446012e-01   1.60710946e-01]\n",
      " [  8.31006735e-04   2.79379517e-01   2.57190913e-02   2.91243829e-02\n",
      "    1.27812743e-03   6.14370942e-01   1.07751575e-05   1.18950877e-04\n",
      "    4.86098975e-02   5.57286199e-04]\n",
      " [  3.78914387e-03   5.80780208e-01   9.25628061e-04   2.20615752e-02\n",
      "    2.04002298e-02   2.84715462e-02   2.02151659e-05   2.98053771e-01\n",
      "    1.95240558e-04   4.53024730e-02]\n",
      " [  6.33138519e-09   2.22205726e-05   9.85968427e-07   5.28990968e-05\n",
      "    5.85772204e-06   4.02654496e-06   8.72500081e-08   9.99776661e-01\n",
      "    1.19254983e-04   1.80623720e-05]\n",
      " [  9.95474160e-01   1.68977931e-05   1.21457422e-04   7.65612989e-04\n",
      "    7.39858879e-05   3.72766990e-05   7.30728614e-04   2.65822637e-05\n",
      "    2.52178917e-03   2.31610102e-04]\n",
      " [  8.56117040e-05   1.72826392e-03   1.24908314e-04   5.37726562e-04\n",
      "    2.88163662e-01   1.56638604e-02   6.91901799e-03   4.80926126e-01\n",
      "    8.45747143e-02   1.21276140e-01]\n",
      " [  1.34608272e-05   3.43628722e-04   6.65016851e-05   1.45470127e-04\n",
      "    1.40360848e-04   4.65881676e-05   7.83685508e-08   9.68050838e-01\n",
      "    1.42385531e-03   2.97691207e-02]\n",
      " [  5.66081749e-03   6.79595590e-01   4.40223627e-02   7.02769542e-03\n",
      "    2.03466546e-02   1.16911538e-01   2.17517318e-05   1.52705482e-03\n",
      "    1.08212754e-01   1.66737176e-02]\n",
      " [  1.75654102e-04   5.53791225e-03   1.27464175e-01   7.09478021e-01\n",
      "    1.23366481e-02   7.28077069e-03   2.93623889e-04   1.69679377e-04\n",
      "    1.36674657e-01   5.88920491e-04]\n",
      " [  8.23651135e-05   2.69953830e-06   1.45852100e-04   6.09792332e-05\n",
      "    9.94476140e-01   2.98022467e-04   1.80780786e-04   2.20751273e-03\n",
      "    3.13182536e-05   2.51429505e-03]\n",
      " [  7.25251622e-03   1.36077302e-04   9.31518674e-01   2.20641232e-05\n",
      "    6.09269328e-02   7.65599834e-05   2.22226972e-05   1.03587572e-05\n",
      "    2.74754348e-05   7.06562196e-06]\n",
      " [  2.19606775e-07   9.99677062e-01   3.94255767e-05   4.68707367e-06\n",
      "    1.48009349e-04   4.83447002e-06   2.30855630e-06   5.80589403e-05\n",
      "    9.57235079e-06   5.57773637e-05]\n",
      " [  2.18675984e-03   2.98623108e-05   9.96529400e-01   1.57626098e-04\n",
      "    5.41016707e-05   1.02175563e-03   1.38528858e-05   2.96233083e-07\n",
      "    4.24396831e-06   2.03264608e-06]\n",
      " [  9.89144266e-01   3.85190942e-05   4.81767952e-03   4.71330022e-05\n",
      "    2.00281147e-06   1.57802040e-03   4.34145005e-03   3.38596283e-06\n",
      "    1.30448352e-05   1.43936013e-05]\n",
      " [  2.59383341e-06   3.33862402e-03   1.31988738e-04   1.42013878e-01\n",
      "    4.95066866e-03   9.47909895e-03   2.04708394e-05   7.59982243e-02\n",
      "    1.12639843e-02   7.52800524e-01]\n",
      " [  1.37361887e-04   1.15053765e-04   5.28485980e-04   5.56025247e-04\n",
      "    2.30825990e-02   2.28969567e-03   9.64956820e-01   4.46810373e-05\n",
      "    8.15214869e-03   1.37129944e-04]\n",
      " [  3.67386252e-01   1.76179723e-03   2.28960693e-01   1.56913698e-02\n",
      "    2.19153211e-04   2.89605230e-01   2.17344309e-03   3.42485565e-03\n",
      "    9.05098170e-02   2.67390569e-04]\n",
      " [  2.49097036e-04   6.39698119e-05   2.48933880e-04   9.30569828e-01\n",
      "    7.99783902e-06   4.42922581e-04   3.03017744e-09   3.92713491e-03\n",
      "    6.09650239e-02   3.52503825e-03]\n",
      " [  4.40229196e-03   1.51649237e-01   3.40553224e-02   1.08045854e-01\n",
      "    3.21039744e-03   9.59117711e-02   4.11346275e-03   4.53290110e-03\n",
      "    5.91360509e-01   2.71826633e-03]\n",
      " [  2.23257706e-01   1.47498041e-01   4.03620116e-02   1.29624284e-04\n",
      "    2.71495402e-01   5.41290268e-04   2.64492422e-01   8.65259426e-05\n",
      "    2.57308851e-03   4.95639481e-02]\n",
      " [  7.66677439e-01   3.20309482e-04   1.52408227e-01   8.12706348e-05\n",
      "    3.79756372e-03   1.04257725e-02   2.19609737e-02   8.47359945e-04\n",
      "    4.34586443e-02   2.24448813e-05]\n",
      " [  9.98136282e-01   1.32896035e-04   4.49234540e-05   2.73763173e-04\n",
      "    1.79030048e-05   2.68169242e-04   5.76699540e-06   1.26193854e-05\n",
      "    2.69035172e-05   1.08090707e-03]\n",
      " [  5.22828707e-03   5.27502224e-03   2.79795945e-01   2.67153293e-01\n",
      "    8.35284955e-05   9.46452282e-03   4.91406024e-03   4.12810534e-01\n",
      "    8.18219222e-03   7.09257694e-03]\n",
      " [  9.68350351e-01   1.92742937e-06   7.97051052e-06   1.11973938e-03\n",
      "    4.24248101e-05   2.80613136e-02   7.64865952e-04   1.75652531e-04\n",
      "    1.41762593e-03   5.80608830e-05]\n",
      " [  8.58418167e-01   8.34000912e-06   1.28003925e-01   8.56716558e-03\n",
      "    5.96996106e-04   7.24742189e-04   1.50061111e-04   8.01850456e-06\n",
      "    3.36306286e-03   1.59633390e-04]\n",
      " [  5.46859682e-01   8.11707985e-04   7.52787665e-03   9.95898247e-03\n",
      "    8.90928134e-02   2.57747304e-02   1.23467535e-01   1.14490520e-02\n",
      "    6.89734146e-02   1.16084233e-01]\n",
      " [  6.64416850e-02   3.48064769e-03   6.28114715e-02   4.98945999e-04\n",
      "    5.16117609e-04   6.34316057e-02   3.73956487e-02   1.78429618e-04\n",
      "    7.59151578e-01   6.09387457e-03]\n",
      " [  4.26847022e-03   1.50232390e-02   1.83198862e-02   1.48724109e-01\n",
      "    4.90699522e-02   3.82128707e-03   2.84356880e-03   4.12260741e-02\n",
      "    1.85953304e-02   6.98108077e-01]\n",
      " [  7.37002438e-06   5.04297437e-03   9.72282708e-01   5.93618257e-03\n",
      "    6.62282982e-04   2.28981487e-04   5.43533897e-05   9.69567802e-03\n",
      "    6.08642073e-03   3.04140258e-06]\n",
      " [  2.61359510e-05   2.13692076e-07   1.38088251e-06   4.58451845e-02\n",
      "    3.63594212e-04   2.48166634e-06   9.57498614e-09   9.47503209e-01\n",
      "    7.87428435e-05   6.17892947e-03]\n",
      " [  4.02278829e-06   5.22559043e-04   3.18253224e-05   4.16763499e-02\n",
      "    8.82617354e-01   1.69903205e-06   1.85414741e-04   3.60554047e-02\n",
      "    8.62446497e-04   3.80429663e-02]\n",
      " [  9.80276335e-03   4.49546606e-05   6.11889642e-04   6.27660775e-04\n",
      "    1.56282203e-03   1.44105926e-02   9.71352398e-01   4.98099362e-05\n",
      "    1.34645391e-03   1.90764258e-04]\n",
      " [  2.01801569e-07   3.70670634e-04   3.43184729e-05   1.53518245e-02\n",
      "    3.17502804e-06   4.25220242e-05   3.21147600e-05   9.80972886e-01\n",
      "    4.41563643e-05   3.14825703e-03]\n",
      " [  7.69518018e-02   1.47715281e-03   7.56905854e-01   1.67496633e-04\n",
      "    5.98824630e-03   3.75036779e-03   1.29390589e-03   2.57896585e-03\n",
      "    8.03079631e-04   1.50083154e-01]\n",
      " [  4.94918531e-05   6.59179714e-05   1.44132078e-04   4.95371351e-05\n",
      "    3.93658638e-06   1.18887266e-02   4.42744977e-06   4.15471841e-05\n",
      "    9.87692416e-01   5.97571816e-05]\n",
      " [  5.75808983e-04   6.48835022e-03   6.30529539e-05   4.42348281e-03\n",
      "    7.05445185e-02   3.33975861e-03   1.90380756e-02   7.32542694e-01\n",
      "    8.39875918e-03   1.54585510e-01]\n",
      " [  3.42726889e-06   1.04025698e-04   9.90040243e-01   6.03980524e-03\n",
      "    3.11679137e-03   5.61630040e-05   5.40440960e-04   3.24504322e-06\n",
      "    6.78292927e-05   2.80079639e-05]\n",
      " [  1.99424176e-05   9.88280654e-01   1.43061159e-03   1.06051295e-04\n",
      "    7.23855628e-04   1.45295955e-04   6.06645038e-03   2.21868744e-03\n",
      "    7.91047118e-04   2.17438414e-04]\n",
      " [  1.77709237e-02   1.95281534e-03   8.35263729e-03   4.63863090e-03\n",
      "    6.02313161e-01   1.23957857e-01   6.24616659e-05   4.11662422e-02\n",
      "    1.95418194e-01   4.36708424e-03]\n",
      " [  2.84424482e-06   3.01913824e-05   1.66886082e-06   2.98443250e-04\n",
      "    4.75140894e-03   1.14166178e-05   9.45458112e-09   1.41348327e-02\n",
      "    1.34878606e-02   9.67281342e-01]\n",
      " [  7.97068424e-06   2.18571671e-07   4.50141033e-06   2.57031119e-04\n",
      "    1.35669607e-05   7.86454126e-04   5.29608485e-07   9.97169912e-01\n",
      "    5.64416296e-05   1.70330424e-03]\n",
      " [  9.38120857e-03   7.42595568e-02   1.36118347e-03   2.53690928e-02\n",
      "    5.10114385e-03   4.14773822e-03   3.46598146e-03   2.24391907e-01\n",
      "    4.72106636e-02   6.05311513e-01]\n",
      " [  7.71457388e-04   4.49247862e-04   4.90761176e-02   9.49132860e-01\n",
      "    2.41714656e-06   1.47973391e-04   3.17516492e-06   2.86323135e-04\n",
      "    8.76378108e-05   4.27845189e-05]\n",
      " [  1.12825036e-01   4.36763017e-04   7.47183040e-02   1.18273655e-02\n",
      "    3.48515366e-03   1.86283104e-02   4.15304066e-06   1.50892898e-04\n",
      "    7.77833223e-01   9.07454087e-05]\n",
      " [  1.15849762e-05   4.07936068e-06   9.34891868e-05   7.93664753e-07\n",
      "    3.95159586e-05   9.99639034e-01   6.76408235e-05   1.16165183e-05\n",
      "    1.80743591e-05   1.14189352e-04]\n",
      " [  1.77562441e-04   9.57112432e-01   9.82568599e-04   1.03081611e-03\n",
      "    5.75958891e-03   8.26065021e-04   8.45584832e-03   8.15606763e-05\n",
      "    2.54913606e-02   8.22689908e-05]\n",
      " [  1.42372357e-07   2.62484889e-07   9.99988675e-01   2.80993163e-06\n",
      "    4.37505946e-07   2.85131136e-06   1.40558356e-07   4.24018998e-09\n",
      "    4.58597424e-06   6.83266421e-08]\n",
      " [  2.34756335e-05   1.03855755e-05   4.40964095e-06   1.01748621e-03\n",
      "    1.01242813e-05   9.82280552e-01   8.62287015e-06   3.08839844e-07\n",
      "    1.66359805e-02   8.60149976e-06]\n",
      " [  2.50841100e-02   6.60450291e-03   3.05362761e-01   4.87116445e-03\n",
      "    6.92633539e-02   2.36608252e-01   4.27756738e-03   1.24194041e-01\n",
      "    1.79759592e-01   4.39746790e-02]\n",
      " [  2.31972760e-10   1.42859164e-07   6.41284004e-08   9.47687653e-08\n",
      "    1.93600704e-06   7.86731320e-08   8.24294688e-10   9.99972701e-01\n",
      "    4.62595189e-08   2.48750075e-05]]\n",
      "INFO:tensorflow:probabilites = [[  3.66497216e-06   1.88316603e-03   9.88328397e-01   3.29124508e-03\n",
      "    1.54679074e-04   5.76855568e-03   1.23530845e-05   1.78384034e-05\n",
      "    2.66191870e-04   2.73902231e-04]\n",
      " [  2.95862034e-02   3.89295638e-01   7.32504250e-03   1.69360207e-03\n",
      "    1.50123879e-01   3.69849876e-02   6.86231256e-02   7.26615661e-04\n",
      "    2.82190055e-01   3.34507823e-02]\n",
      " [  2.71351048e-04   6.98416785e-04   1.22787305e-05   5.65321767e-04\n",
      "    9.96153615e-03   7.95049618e-06   2.18992180e-04   4.71791625e-03\n",
      "    6.23325864e-03   9.77313042e-01]\n",
      " [  1.01419364e-03   6.23921230e-02   3.48286959e-03   3.26495829e-05\n",
      "    4.64902192e-01   2.01651286e-02   1.69854105e-01   8.29955796e-04\n",
      "    2.65217096e-01   1.21096224e-02]\n",
      " [  1.18316138e-05   3.18934713e-06   2.13537496e-05   4.47894166e-07\n",
      "    1.80852439e-05   1.88450576e-04   9.99647856e-01   1.61059324e-05\n",
      "    9.19964441e-05   6.59347620e-07]\n",
      " [  6.48613366e-07   2.06870551e-04   1.30664439e-05   3.01860132e-06\n",
      "    1.62222165e-07   9.97300208e-01   5.85231173e-05   2.43872473e-05\n",
      "    2.35510687e-03   3.79200501e-05]\n",
      " [  7.51573025e-05   1.51583135e-05   6.81265647e-07   8.03918054e-04\n",
      "    1.10413248e-05   9.95882511e-01   1.02907882e-06   2.44469848e-05\n",
      "    3.18136089e-03   4.64434606e-06]\n",
      " [  4.35999921e-03   4.01187651e-02   3.27513646e-03   3.61199945e-01\n",
      "    6.90582920e-06   5.48884571e-01   5.12591912e-04   1.00001867e-04\n",
      "    3.88917439e-02   2.65042158e-03]\n",
      " [  1.67325852e-05   9.54020321e-01   3.89444642e-03   6.60150871e-03\n",
      "    1.04463389e-02   2.94311997e-03   7.03068159e-04   1.44725273e-04\n",
      "    2.02764105e-02   9.53276234e-04]\n",
      " [  8.28834891e-04   1.76931934e-07   9.98800874e-01   3.08964838e-04\n",
      "    5.98737142e-06   6.23576898e-06   8.41994643e-06   1.11892426e-07\n",
      "    3.54271651e-05   4.93883999e-06]\n",
      " [  1.18814956e-03   9.23116295e-06   2.63217767e-03   3.24619492e-03\n",
      "    6.50609732e-01   1.14824984e-03   3.98862525e-04   1.26625197e-02\n",
      "    5.82815753e-03   3.22276711e-01]\n",
      " [  5.43994713e-04   2.09846394e-03   2.97623483e-04   4.09079366e-04\n",
      "    1.30855706e-05   1.92670769e-03   1.75745969e-04   2.99984543e-03\n",
      "    9.81697857e-01   9.83753055e-03]\n",
      " [  3.42268795e-05   2.90644221e-06   1.14579075e-06   9.99613941e-01\n",
      "    1.43527586e-07   5.05528005e-05   1.35066898e-06   2.29190817e-04\n",
      "    1.19969618e-05   5.45897637e-05]\n",
      " [  6.19701314e-06   6.53408424e-05   7.91792851e-03   4.32292402e-01\n",
      "    3.84350191e-04   3.84404480e-01   1.39197175e-04   1.62457332e-01\n",
      "    1.20755788e-02   2.57303676e-04]\n",
      " [  9.02075022e-02   8.58399260e-04   2.28743404e-02   1.60460118e-02\n",
      "    1.52727182e-04   1.13695126e-03   6.71284180e-03   3.69035028e-04\n",
      "    8.61620128e-01   2.20814964e-05]\n",
      " [  2.18399265e-03   1.50671131e-05   2.99152220e-03   6.40501082e-01\n",
      "    9.87855531e-03   2.53402907e-03   1.42573390e-05   3.27436184e-03\n",
      "    1.98560562e-02   3.18751097e-01]\n",
      " [  2.03181133e-02   1.38381915e-03   9.57198024e-01   1.25397546e-02\n",
      "    1.01434172e-03   1.99053884e-05   6.09083148e-03   8.81748929e-05\n",
      "    1.28070556e-03   6.63520623e-05]\n",
      " [  2.57086125e-03   4.94935177e-02   6.23220624e-03   1.18201688e-01\n",
      "    2.63108220e-02   3.63070995e-01   4.00127023e-02   2.42151797e-01\n",
      "    6.49725869e-02   8.69828165e-02]\n",
      " [  9.96426880e-01   1.68141578e-05   6.12708973e-04   2.13961699e-03\n",
      "    6.41576571e-06   1.97006899e-04   7.31672799e-06   5.05999720e-04\n",
      "    2.88254832e-05   5.83473666e-05]\n",
      " [  4.99417586e-03   3.73451949e-05   1.87188704e-02   9.65303957e-01\n",
      "    9.57061275e-07   5.31554734e-03   5.61246043e-03   5.79931202e-06\n",
      "    4.80824338e-06   6.13959355e-06]\n",
      " [  2.55079125e-04   2.24764153e-04   1.32211586e-02   9.58874941e-01\n",
      "    1.60843938e-05   1.57487579e-02   4.88192512e-04   1.74768520e-05\n",
      "    1.11082811e-02   4.52296808e-05]\n",
      " [  1.14848866e-04   8.50329525e-05   4.55637433e-04   7.41178589e-03\n",
      "    2.23237119e-04   4.85705119e-03   4.90239108e-05   8.73812497e-01\n",
      "    1.30645814e-03   1.11684449e-01]\n",
      " [  6.21573366e-02   5.36190532e-02   1.77173372e-02   4.37740535e-02\n",
      "    2.80226523e-04   1.64669808e-02   3.92321730e-04   6.88849468e-06\n",
      "    8.04973960e-01   6.11832016e-04]\n",
      " [  1.24135680e-04   1.23026781e-04   5.29990904e-03   2.42074914e-02\n",
      "    3.01949680e-01   9.45057473e-05   1.39687052e-02   3.17257736e-03\n",
      "    6.50828183e-01   2.31708618e-04]\n",
      " [  1.31409755e-02   1.52867506e-05   3.68610286e-04   2.99433782e-06\n",
      "    2.71483138e-02   1.05166854e-03   9.57934678e-01   4.16020885e-06\n",
      "    3.10287054e-04   2.30409132e-05]\n",
      " [  3.64314835e-03   9.42207498e-06   6.63125002e-06   3.90519172e-01\n",
      "    3.34495853e-05   6.05559826e-01   4.95700660e-05   1.36618382e-06\n",
      "    1.55717775e-04   2.17474699e-05]\n",
      " [  1.16171711e-03   9.87439871e-01   8.70337419e-04   4.82155701e-05\n",
      "    3.23286327e-03   1.17966381e-03   2.34194985e-03   4.78315960e-05\n",
      "    3.66914785e-03   8.29351484e-06]\n",
      " [  3.46744014e-06   9.99209762e-01   1.95161028e-05   1.08742825e-04\n",
      "    1.54695546e-04   5.11451399e-05   2.37394561e-04   2.40863956e-05\n",
      "    1.90313425e-04   9.11180848e-07]\n",
      " [  1.20024561e-04   1.09324981e-06   9.86396432e-01   4.01313300e-04\n",
      "    6.16689385e-06   2.43107570e-06   1.30038662e-02   2.75484854e-06\n",
      "    6.58130157e-05   1.15720262e-07]\n",
      " [  3.61368200e-03   1.44083041e-03   9.05585229e-01   1.54696153e-02\n",
      "    1.61483209e-03   1.85834046e-03   3.36199795e-04   3.24093329e-04\n",
      "    1.49775518e-03   6.82593957e-02]\n",
      " [  8.02887797e-01   2.82330788e-04   4.68013296e-03   3.21460748e-03\n",
      "    8.12245812e-03   5.46027673e-04   1.78662181e-01   5.54869439e-05\n",
      "    1.26130797e-03   2.87588453e-04]\n",
      " [  3.38386260e-02   1.61139324e-05   9.63476479e-01   9.45128035e-04\n",
      "    2.79522574e-05   2.00837603e-05   1.20417673e-04   1.27593685e-05\n",
      "    1.53891230e-03   3.62012588e-06]\n",
      " [  1.05959196e-04   3.52401927e-04   3.22402934e-06   1.73468981e-03\n",
      "    1.99338514e-03   9.93192852e-01   2.37629029e-05   2.94594793e-04\n",
      "    2.29776953e-03   1.39613326e-06]\n",
      " [  3.75094567e-03   3.27292178e-03   9.65097785e-01   2.15688930e-03\n",
      "    1.09733073e-02   1.54101451e-06   7.51035928e-04   7.26062935e-05\n",
      "    1.34791574e-03   1.25750145e-02]\n",
      " [  3.60162448e-06   3.05782087e-05   1.37583368e-06   3.64876701e-06\n",
      "    9.66076910e-01   2.61224468e-05   1.97666373e-06   8.29354220e-04\n",
      "    1.54090775e-02   1.76174343e-02]\n",
      " [  8.45623526e-06   2.28172189e-06   4.87916374e-09   3.25365107e-07\n",
      "    3.01784610e-07   9.98986185e-01   7.89900582e-07   1.62247807e-06\n",
      "    9.96725983e-04   3.36039079e-06]\n",
      " [  9.96177079e-08   5.22491391e-05   3.46379420e-05   5.88807379e-05\n",
      "    4.11304965e-04   8.81978020e-04   4.66111572e-07   9.88122880e-01\n",
      "    1.60090305e-04   1.02773309e-02]\n",
      " [  2.07303472e-07   1.47119263e-05   1.75629575e-05   3.24422792e-02\n",
      "    1.67597231e-04   1.14683667e-06   2.47251069e-06   9.66891885e-01\n",
      "    9.36697688e-07   4.61102318e-04]\n",
      " [  1.10599751e-04   5.64749257e-07   5.89811543e-06   1.14939986e-02\n",
      "    1.56190272e-05   9.78252709e-01   6.41154964e-03   2.23854440e-03\n",
      "    1.19323400e-03   2.77179352e-04]\n",
      " [  9.98876393e-01   8.69887856e-07   1.36541976e-05   9.00545183e-06\n",
      "    4.18247600e-06   8.65254202e-04   2.14223852e-04   3.46999570e-07\n",
      "    1.25777451e-05   3.48626759e-06]\n",
      " [  4.43866942e-03   6.48025089e-05   3.39432023e-02   1.08546922e-02\n",
      "    1.46087361e-04   5.35238326e-01   3.88397370e-04   2.20149998e-02\n",
      "    1.45558426e-02   3.78354907e-01]\n",
      " [  2.55840951e-05   9.04634217e-05   5.43214497e-04   2.42391042e-03\n",
      "    1.65056973e-03   2.52360571e-02   1.25361228e-04   8.99761021e-01\n",
      "    1.75644259e-03   6.83874339e-02]\n",
      " [  1.75334426e-05   1.90009050e-05   3.72126815e-05   9.88839209e-01\n",
      "    2.40971985e-05   3.24161560e-03   1.12910660e-04   1.34525078e-04\n",
      "    6.03009108e-03   1.54377834e-03]\n",
      " [  1.62227407e-05   6.12131844e-05   4.61521506e-01   2.38128214e-05\n",
      "    3.03180851e-02   1.72494985e-02   1.48891180e-04   4.87292349e-01\n",
      "    3.07272167e-05   3.33770411e-03]\n",
      " [  2.57332053e-04   3.45257854e-06   7.01957251e-05   1.17191412e-05\n",
      "    1.75606355e-03   8.28573538e-04   9.96791422e-01   2.38392590e-06\n",
      "    2.76199717e-04   2.51665506e-06]\n",
      " [  1.25006295e-03   7.05876589e-01   1.00489058e-01   8.66859704e-02\n",
      "    3.55843678e-02   1.74620971e-02   1.29919557e-03   3.35309096e-03\n",
      "    1.11785680e-02   3.68209854e-02]\n",
      " [  4.23868102e-07   5.10194650e-06   1.00788457e-05   4.78338279e-06\n",
      "    5.51241501e-05   9.79575998e-06   3.91265621e-06   1.60663261e-03\n",
      "    4.13445174e-04   9.97890651e-01]\n",
      " [  7.38039985e-03   1.43453153e-02   1.54673271e-02   1.68815069e-02\n",
      "    9.58602875e-04   8.29303116e-02   9.37271107e-05   2.47348174e-02\n",
      "    8.31587970e-01   5.62008563e-03]\n",
      " [  5.32829017e-06   8.88488488e-04   3.68640872e-06   2.55827210e-03\n",
      "    7.46354818e-01   2.27938915e-04   1.13883892e-04   4.40609781e-03\n",
      "    2.11897260e-03   2.43322507e-01]\n",
      " [  2.52740122e-08   3.67025592e-08   7.05882314e-07   3.04849291e-05\n",
      "    8.04368483e-08   1.61934186e-05   5.25351673e-09   9.99943852e-01\n",
      "    1.74487184e-07   8.40214034e-06]\n",
      " [  2.46533081e-01   2.75699480e-04   6.77498290e-03   1.06533815e-03\n",
      "    3.85850412e-03   1.82263704e-03   7.35799491e-01   1.02879108e-04\n",
      "    3.60747427e-03   1.59965624e-04]\n",
      " [  1.21039782e-04   1.31130149e-03   4.70442697e-03   2.93408725e-02\n",
      "    1.67272706e-02   1.86499296e-04   7.92055216e-05   6.02521114e-02\n",
      "    1.46276485e-02   8.72649610e-01]\n",
      " [  9.22023219e-07   9.98355925e-01   1.29700456e-05   1.55666885e-06\n",
      "    5.64887421e-04   3.03308548e-06   9.07632057e-06   7.46398058e-04\n",
      "    2.75303872e-04   3.00018728e-05]\n",
      " [  1.41734234e-03   2.73892015e-01   3.65715884e-02   1.80405639e-02\n",
      "    2.87080165e-02   3.02078605e-01   1.57338269e-02   1.96854156e-02\n",
      "    3.03766429e-01   1.06261505e-04]\n",
      " [  1.45362481e-01   1.67112239e-02   1.39775276e-01   5.97803816e-02\n",
      "    4.57161060e-03   1.22790761e-01   2.29171112e-01   2.36975104e-02\n",
      "    2.47064710e-01   1.10748624e-02]\n",
      " [  9.67962667e-04   3.74290645e-02   4.00862902e-01   5.65336086e-03\n",
      "    3.79573524e-01   1.79995201e-04   1.66822504e-03   1.45014306e-03\n",
      "    1.19545567e-03   1.71019405e-01]\n",
      " [  1.50749533e-04   4.30747382e-02   6.29725691e-04   8.31368379e-04\n",
      "    3.91259789e-03   1.33010244e-03   3.14821256e-04   3.72153744e-02\n",
      "    5.13381744e-03   9.07406747e-01]\n",
      " [  6.40996877e-05   2.74317688e-03   4.93489858e-03   9.55035329e-01\n",
      "    1.30619726e-03   2.74788626e-02   2.05244622e-04   8.24613904e-04\n",
      "    8.94582539e-04   6.51297346e-03]\n",
      " [  7.62983167e-04   8.26498687e-01   1.36184804e-02   9.84648522e-03\n",
      "    5.81897516e-03   2.42665373e-02   1.58501684e-03   1.96150155e-03\n",
      "    1.09371126e-01   6.27024798e-03]\n",
      " [  1.23782147e-05   3.38277205e-05   3.91163677e-02   9.60471153e-01\n",
      "    1.25230929e-06   3.50050948e-04   2.50636134e-08   2.95378044e-07\n",
      "    5.36509879e-06   9.22564504e-06]\n",
      " [  1.00246485e-04   1.07021770e-02   1.09471977e-04   8.90706026e-04\n",
      "    1.46470562e-01   5.67656709e-03   4.38902149e-04   4.91364598e-01\n",
      "    5.49493264e-03   3.38751882e-01]\n",
      " [  2.89010859e-06   1.99238621e-05   3.47696914e-06   2.14221618e-05\n",
      "    2.40659188e-06   2.92570367e-05   1.34237993e-07   9.99579251e-01\n",
      "    3.27228423e-04   1.39345357e-05]\n",
      " [  1.88368256e-06   1.13248717e-07   7.79929059e-03   9.62888777e-01\n",
      "    5.13803889e-06   2.82383393e-02   3.09461567e-10   6.56737893e-06\n",
      "    1.05798931e-03   1.98176531e-06]\n",
      " [  1.90962877e-04   3.05132219e-03   8.87297273e-01   1.78653700e-03\n",
      "    1.05738989e-03   1.52054960e-02   2.79350788e-04   8.22670162e-02\n",
      "    1.08136062e-03   7.78323924e-03]\n",
      " [  1.62363779e-02   7.41294702e-04   3.81343812e-02   2.72121537e-03\n",
      "    3.49525106e-03   4.89739608e-03   8.02868046e-04   8.99983663e-03\n",
      "    2.71745443e-01   6.52225912e-01]\n",
      " [  9.97746646e-01   4.95415543e-06   9.71185946e-05   5.67934476e-04\n",
      "    5.71551755e-05   1.24603184e-03   1.69397215e-04   2.00405111e-06\n",
      "    1.06364860e-04   2.17300908e-06]\n",
      " [  1.71711981e-05   1.43953303e-05   4.02455100e-08   3.07454798e-06\n",
      "    1.93424671e-06   9.99408484e-01   6.98674603e-06   4.69508785e-04\n",
      "    7.68699319e-05   1.53372946e-06]\n",
      " [  7.15742877e-04   5.24472343e-05   2.74048002e-08   5.66893583e-03\n",
      "    1.92329369e-03   9.88502741e-01   8.17861815e-04   5.98467159e-05\n",
      "    4.85462340e-04   1.77368429e-03]\n",
      " [  9.98607218e-01   3.17789750e-06   9.15215292e-04   1.24062659e-04\n",
      "    2.57468378e-06   3.33395910e-05   3.03809094e-04   6.00247449e-06\n",
      "    2.81462076e-06   1.84737382e-06]\n",
      " [  9.67072785e-01   3.43937916e-03   6.02025597e-04   6.91311713e-03\n",
      "    3.46788511e-05   1.04506128e-02   2.58687924e-05   6.63816812e-04\n",
      "    6.33240864e-03   4.46531503e-03]\n",
      " [  2.88587398e-05   9.77885187e-01   3.80025734e-03   8.98119761e-05\n",
      "    2.55960692e-03   1.27580395e-04   1.33643698e-04   2.60995002e-04\n",
      "    1.44400680e-02   6.74033188e-04]\n",
      " [  9.96703923e-01   1.25651377e-06   1.26595396e-05   9.83907012e-05\n",
      "    6.51615337e-05   9.17435391e-05   2.99389218e-03   4.21222694e-07\n",
      "    2.64331029e-05   6.25486518e-06]\n",
      " [  9.85790248e-05   9.13564691e-06   1.45190670e-05   9.55442488e-07\n",
      "    9.99274790e-01   6.95319322e-05   2.47689741e-07   2.01931995e-04\n",
      "    3.11325828e-04   1.88744307e-05]\n",
      " [  3.35592590e-03   9.85784936e-05   7.25202117e-05   8.03990737e-02\n",
      "    1.68174691e-02   1.17529929e-03   1.29354143e-04   1.11142911e-01\n",
      "    7.66024226e-04   7.86042809e-01]\n",
      " [  9.79994416e-01   3.24951805e-04   4.72760366e-05   1.88458271e-05\n",
      "    7.71855412e-05   4.39662283e-04   1.44958422e-02   4.71974490e-04\n",
      "    3.79749411e-03   3.32335621e-04]\n",
      " [  2.11245288e-06   1.57872967e-06   2.97474367e-06   1.44114354e-04\n",
      "    3.31463610e-07   3.75292598e-06   1.47133301e-06   9.99718249e-01\n",
      "    1.19965945e-04   5.38915947e-06]\n",
      " [  8.57187299e-09   1.15207990e-06   9.84485149e-01   1.54937161e-02\n",
      "    1.93617311e-07   1.31245500e-07   7.84637109e-07   1.30615817e-07\n",
      "    1.83963475e-05   2.59736765e-07]\n",
      " [  1.01968602e-04   9.98800874e-01   9.49554487e-06   6.94403861e-05\n",
      "    3.71339353e-04   1.23931910e-04   3.65792745e-04   4.34239482e-05\n",
      "    1.01554309e-04   1.21170006e-05]\n",
      " [  6.55924857e-01   2.60222150e-04   6.52661663e-04   4.87263424e-05\n",
      "    4.18429226e-02   8.72574095e-03   1.37311881e-05   2.91421950e-01\n",
      "    3.38664249e-04   7.70547078e-04]\n",
      " [  1.13167819e-02   1.54385110e-03   9.34556425e-02   2.30351230e-03\n",
      "    5.72093487e-01   1.57962628e-02   2.16898159e-03   6.15353510e-03\n",
      "    2.88686812e-01   6.48113200e-03]\n",
      " [  7.26864021e-03   9.64207924e-04   7.67218292e-01   8.80345106e-05\n",
      "    1.34818675e-02   4.21552733e-03   3.21667194e-02   1.91752159e-03\n",
      "    1.51038364e-01   2.16407888e-02]\n",
      " [  4.60865945e-02   6.00792482e-05   8.93839836e-01   6.07165322e-03\n",
      "    2.06798853e-04   6.01114612e-03   3.13381441e-02   7.40246105e-06\n",
      "    1.63768623e-02   1.57940303e-06]\n",
      " [  4.06729196e-05   4.64408004e-05   3.05221761e-06   1.03427621e-03\n",
      "    3.79289361e-07   9.98034537e-01   1.53374189e-04   2.75685193e-06\n",
      "    6.84374128e-04   1.92334412e-07]\n",
      " [  8.73153214e-04   8.03955138e-01   1.96951870e-02   3.70778469e-03\n",
      "    2.05376670e-02   2.45522265e-03   3.91913578e-02   8.95044804e-02\n",
      "    1.20841134e-02   7.99581781e-03]\n",
      " [  2.34347608e-05   4.00770718e-04   9.70243011e-04   2.82359403e-02\n",
      "    2.21882419e-05   5.27090859e-04   4.24519249e-06   5.16845472e-03\n",
      "    9.64532435e-01   1.15154617e-04]\n",
      " [  8.12285487e-03   6.86562993e-03   2.26206873e-02   2.34820113e-01\n",
      "    1.60163312e-04   6.86322808e-01   5.02997427e-04   1.26028350e-02\n",
      "    2.68971454e-02   1.08477555e-03]\n",
      " [  1.06322514e-02   3.11963959e-05   4.09214481e-05   4.64385848e-05\n",
      "    7.37299095e-04   9.83577609e-01   6.17883125e-05   8.86755064e-04\n",
      "    3.30877909e-03   6.76941650e-04]\n",
      " [  2.38132161e-05   1.42502549e-05   6.99029406e-05   1.82239048e-03\n",
      "    3.60479717e-05   9.97989297e-01   1.65942238e-05   1.31828313e-06\n",
      "    2.57818374e-05   5.81408983e-07]\n",
      " [  1.03726357e-04   3.19092255e-03   9.96250719e-07   7.70411425e-05\n",
      "    4.14102804e-03   8.45778035e-04   1.57680734e-05   9.19312716e-01\n",
      "    1.09564345e-02   6.13556281e-02]\n",
      " [  1.77493747e-02   4.65727806e-01   1.37134865e-02   2.93212365e-02\n",
      "    1.03059433e-01   1.84193850e-02   7.11500458e-03   9.45313275e-03\n",
      "    3.34543228e-01   8.97954742e-04]\n",
      " [  1.99169107e-03   3.92427808e-03   1.11013046e-03   8.93237412e-01\n",
      "    3.63622024e-03   3.26624550e-02   1.08739832e-05   7.77821060e-06\n",
      "    6.10425249e-02   2.37660995e-03]\n",
      " [  3.07898040e-06   2.01468793e-04   8.16223320e-08   4.07746811e-05\n",
      "    2.10180320e-03   2.22288272e-05   1.69410885e-06   2.13545142e-03\n",
      "    4.28653322e-04   9.95064795e-01]\n",
      " [  5.81313740e-04   7.10353721e-04   6.32982177e-04   5.14144660e-04\n",
      "    9.03691173e-01   2.77851475e-03   3.35519994e-03   2.31771218e-03\n",
      "    9.44042840e-05   8.53242055e-02]\n",
      " [  7.75476510e-05   1.26329542e-05   2.31802933e-05   2.60641427e-05\n",
      "    1.11699023e-03   5.07487333e-04   9.98043776e-01   3.46564266e-05\n",
      "    4.11521469e-05   1.16513220e-04]\n",
      " [  3.03652614e-09   1.53650646e-07   2.28414865e-06   5.35563122e-05\n",
      "    8.80052298e-08   1.59979902e-06   9.07435371e-09   9.99842644e-01\n",
      "    4.48260067e-07   9.92247151e-05]\n",
      " [  1.02198590e-03   9.37224388e-01   3.48872412e-03   4.58611036e-03\n",
      "    5.34332218e-03   1.69184845e-04   3.13217007e-02   2.43394883e-04\n",
      "    1.49250310e-02   1.67622289e-03]\n",
      " [  8.71076481e-05   1.02154016e-04   5.87715913e-05   7.34524045e-04\n",
      "    3.35464515e-02   8.50221899e-04   2.96131067e-04   1.06384359e-04\n",
      "    1.37976534e-03   9.62838471e-01]\n",
      " [  4.61372038e-05   9.87696350e-01   7.12354202e-04   6.80640980e-04\n",
      "    2.09276732e-05   4.80622519e-04   5.57847787e-03   8.92552562e-05\n",
      "    4.64431616e-03   5.09536912e-05]\n",
      " [  1.00295452e-04   9.60494995e-01   3.37462989e-03   1.78646500e-04\n",
      "    6.59800181e-03   4.85059310e-04   1.49996358e-03   4.91207116e-04\n",
      "    2.13717334e-02   5.40551078e-03]\n",
      " [  2.07301287e-08   1.30851826e-04   1.66280995e-06   4.82957648e-06\n",
      "    3.51848546e-04   1.01142425e-04   2.33501851e-06   9.94096518e-01\n",
      "    2.35265019e-04   5.07547939e-03]]\n",
      "INFO:tensorflow:Saving checkpoints for 200 into /Users/najeebkhan/Desktop/GitHub/Tensorflow-CS20SI/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.475399.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SKCompat()"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_estimator.fit(x=X_train.astype(np.float32),y=y_train.astype(np.int64),batch_size=100,steps=200,monitors=[logging_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics = {\"accuracy\" : tf.contrib.learn.MetricSpec(metric_fn=tf.metrics.accuracy,prediction_key=\"classes\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-04-23-17:03:27\n",
      "INFO:tensorflow:Finished evaluation at 2017-04-23-17:03:44\n",
      "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.922222, global_step = 200, loss = 0.244891\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9222222, 'global_step': 200, 'loss': 0.24489114}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_estimator.score(x=X_test.astype(np.float32),y=y_test.astype(np.int64),metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Logistic Regression for notMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Dataset/notMNIST_small/A/RGVtb2NyYXRpY2FCb2xkT2xkc3R5bGUgQm9sZC50dGY=.png\n",
      "../../Dataset/notMNIST_small/F/Q3Jvc3NvdmVyIEJvbGRPYmxpcXVlLnR0Zg==.png\n"
     ]
    }
   ],
   "source": [
    "count,images = 0,[]\n",
    "labels,not_read = [],[]\n",
    "for alpha in glob.glob('../../Dataset/notMNIST_small/*'):\n",
    "    label = alpha.split('/')[-1]\n",
    "    for img in glob.glob(os.path.join(alpha,'*')):\n",
    "        try:\n",
    "            im = plt.imread(img)\n",
    "            images.append(im.reshape(28*28))\n",
    "            labels.append(label)\n",
    "        except:\n",
    "            print img\n",
    "            not_read.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18724, 784)\n",
      "(18724,)\n"
     ]
    }
   ],
   "source": [
    "data = np.asarray(images)\n",
    "labels = np.asarray([ord(label) - ord('A') for label in labels])\n",
    "print data.shape\n",
    "print labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18724, 10)\n"
     ]
    }
   ],
   "source": [
    "labels = pd.get_dummies(labels)\n",
    "print labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13106, 784) (13106, 10)\n",
      "(5618, 784) (5618, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(data,labels.values,test_size=0.3,random_state=7)\n",
    "print X_train.shape,y_train.shape\n",
    "print X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_training_data,num_features = X_train.shape\n",
    "num_training_data_cv = X_test.shape[0]\n",
    "num_classes = 10\n",
    "n_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Constructing the Tensorflow model\n",
    "X = tf.placeholder(dtype=tf.float32,shape=[batch_size,num_features],name='X')\n",
    "y = tf.placeholder(dtype=tf.float32,shape=[batch_size,num_classes],name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([num_features,num_classes],mean=0.0,stddev=1.0),dtype=tf.float32)\n",
    "b = tf.Variable(tf.zeros([1,num_classes],dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = tf.matmul(X,W) + b\n",
    "ypred = tf.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits))\n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate=0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tTraining Error: 1173.43497705\tCross Validation Acc: 0.307776162791\n",
      "Epoch: 2\tTraining Error: 694.91395092\tCross Validation Acc: 0.415879360465\n",
      "Epoch: 3\tTraining Error: 518.425346375\tCross Validation Acc: 0.49582122093\n",
      "Epoch: 4\tTraining Error: 430.071502686\tCross Validation Acc: 0.550327034884\n",
      "Epoch: 5\tTraining Error: 378.277494907\tCross Validation Acc: 0.596656976744\n",
      "Epoch: 6\tTraining Error: 344.245657682\tCross Validation Acc: 0.623183139535\n",
      "Epoch: 7\tTraining Error: 319.948605657\tCross Validation Acc: 0.645712209302\n",
      "Epoch: 8\tTraining Error: 301.562520862\tCross Validation Acc: 0.663335755814\n",
      "Epoch: 9\tTraining Error: 287.087151885\tCross Validation Acc: 0.677688953488\n",
      "Epoch: 10\tTraining Error: 275.347707748\tCross Validation Acc: 0.6875\n",
      "Epoch: 11\tTraining Error: 265.583233595\tCross Validation Acc: 0.697492732558\n",
      "Epoch: 12\tTraining Error: 257.289517045\tCross Validation Acc: 0.706031976744\n",
      "Epoch: 13\tTraining Error: 250.127445817\tCross Validation Acc: 0.713662790698\n",
      "Epoch: 14\tTraining Error: 243.857715726\tCross Validation Acc: 0.721293604651\n",
      "Epoch: 15\tTraining Error: 238.304262638\tCross Validation Acc: 0.726199127907\n",
      "Epoch: 16\tTraining Error: 233.334632754\tCross Validation Acc: 0.731104651163\n",
      "Epoch: 17\tTraining Error: 228.847500682\tCross Validation Acc: 0.737281976744\n",
      "Epoch: 18\tTraining Error: 224.763885856\tCross Validation Acc: 0.740915697674\n",
      "Epoch: 19\tTraining Error: 221.021452785\tCross Validation Acc: 0.745457848837\n",
      "Epoch: 20\tTraining Error: 217.570607424\tCross Validation Acc: 0.74945494186\n",
      "Epoch: 21\tTraining Error: 214.371655464\tCross Validation Acc: 0.752361918605\n",
      "Epoch: 22\tTraining Error: 211.392376184\tCross Validation Acc: 0.755632267442\n",
      "Epoch: 23\tTraining Error: 208.606313348\tCross Validation Acc: 0.759629360465\n",
      "Epoch: 24\tTraining Error: 205.991434216\tCross Validation Acc: 0.762172965116\n",
      "Epoch: 25\tTraining Error: 203.529247642\tCross Validation Acc: 0.764898255814\n",
      "Epoch: 26\tTraining Error: 201.20407021\tCross Validation Acc: 0.767623546512\n",
      "Epoch: 27\tTraining Error: 199.002492309\tCross Validation Acc: 0.770893895349\n",
      "Epoch: 28\tTraining Error: 196.912963152\tCross Validation Acc: 0.773255813953\n",
      "Epoch: 29\tTraining Error: 194.925458074\tCross Validation Acc: 0.774709302326\n",
      "Epoch: 30\tTraining Error: 193.031270742\tCross Validation Acc: 0.776707848837\n",
      "Epoch: 31\tTraining Error: 191.222747445\tCross Validation Acc: 0.779251453488\n",
      "Epoch: 32\tTraining Error: 189.49316442\tCross Validation Acc: 0.780886627907\n",
      "Epoch: 33\tTraining Error: 187.836583138\tCross Validation Acc: 0.782703488372\n",
      "Epoch: 34\tTraining Error: 186.24770093\tCross Validation Acc: 0.784702034884\n",
      "Epoch: 35\tTraining Error: 184.721802473\tCross Validation Acc: 0.785973837209\n",
      "Epoch: 36\tTraining Error: 183.254621923\tCross Validation Acc: 0.787609011628\n",
      "Epoch: 37\tTraining Error: 181.842313051\tCross Validation Acc: 0.787790697674\n",
      "Epoch: 38\tTraining Error: 180.481348872\tCross Validation Acc: 0.7890625\n",
      "Epoch: 39\tTraining Error: 179.16850096\tCross Validation Acc: 0.791424418605\n",
      "Epoch: 40\tTraining Error: 177.90079391\tCross Validation Acc: 0.792514534884\n",
      "Epoch: 41\tTraining Error: 176.675481021\tCross Validation Acc: 0.793059593023\n",
      "Epoch: 42\tTraining Error: 175.490039706\tCross Validation Acc: 0.793604651163\n",
      "Epoch: 43\tTraining Error: 174.342150509\tCross Validation Acc: 0.795421511628\n",
      "Epoch: 44\tTraining Error: 173.229674459\tCross Validation Acc: 0.796148255814\n",
      "Epoch: 45\tTraining Error: 172.150656402\tCross Validation Acc: 0.796693313953\n",
      "Epoch: 46\tTraining Error: 171.103284955\tCross Validation Acc: 0.797056686047\n",
      "Epoch: 47\tTraining Error: 170.085895181\tCross Validation Acc: 0.797601744186\n",
      "Epoch: 48\tTraining Error: 169.096968114\tCross Validation Acc: 0.798510174419\n",
      "Epoch: 49\tTraining Error: 168.13507241\tCross Validation Acc: 0.799055232558\n",
      "Epoch: 50\tTraining Error: 167.198895693\tCross Validation Acc: 0.799781976744\n",
      "Epoch: 51\tTraining Error: 166.287202001\tCross Validation Acc: 0.80105377907\n",
      "Epoch: 52\tTraining Error: 165.398864627\tCross Validation Acc: 0.801598837209\n",
      "Epoch: 53\tTraining Error: 164.532817781\tCross Validation Acc: 0.802688953488\n",
      "Epoch: 54\tTraining Error: 163.688064694\tCross Validation Acc: 0.803779069767\n",
      "Epoch: 55\tTraining Error: 162.863676608\tCross Validation Acc: 0.804324127907\n",
      "Epoch: 56\tTraining Error: 162.058780015\tCross Validation Acc: 0.8046875\n",
      "Epoch: 57\tTraining Error: 161.272547901\tCross Validation Acc: 0.806140988372\n",
      "Epoch: 58\tTraining Error: 160.504215896\tCross Validation Acc: 0.806322674419\n",
      "Epoch: 59\tTraining Error: 159.75305438\tCross Validation Acc: 0.807049418605\n",
      "Epoch: 60\tTraining Error: 159.018387973\tCross Validation Acc: 0.807231104651\n",
      "Epoch: 61\tTraining Error: 158.299559653\tCross Validation Acc: 0.807594476744\n",
      "Epoch: 62\tTraining Error: 157.595966935\tCross Validation Acc: 0.807594476744\n",
      "Epoch: 63\tTraining Error: 156.907027543\tCross Validation Acc: 0.807776162791\n",
      "Epoch: 64\tTraining Error: 156.232199371\tCross Validation Acc: 0.807957848837\n",
      "Epoch: 65\tTraining Error: 155.57096076\tCross Validation Acc: 0.808502906977\n",
      "Epoch: 66\tTraining Error: 154.922837436\tCross Validation Acc: 0.80886627907\n",
      "Epoch: 67\tTraining Error: 154.287339211\tCross Validation Acc: 0.809229651163\n",
      "Epoch: 68\tTraining Error: 153.664064586\tCross Validation Acc: 0.809229651163\n",
      "Epoch: 69\tTraining Error: 153.052571893\tCross Validation Acc: 0.810138081395\n",
      "Epoch: 70\tTraining Error: 152.45247525\tCross Validation Acc: 0.810319767442\n",
      "Epoch: 71\tTraining Error: 151.863396823\tCross Validation Acc: 0.810864825581\n",
      "Epoch: 72\tTraining Error: 151.284976244\tCross Validation Acc: 0.810864825581\n",
      "Epoch: 73\tTraining Error: 150.716886103\tCross Validation Acc: 0.810864825581\n",
      "Epoch: 74\tTraining Error: 150.158792913\tCross Validation Acc: 0.811046511628\n",
      "Epoch: 75\tTraining Error: 149.610396504\tCross Validation Acc: 0.810864825581\n",
      "Epoch: 76\tTraining Error: 149.071395516\tCross Validation Acc: 0.811591569767\n",
      "Epoch: 77\tTraining Error: 148.541520417\tCross Validation Acc: 0.81195494186\n",
      "Epoch: 78\tTraining Error: 148.020491302\tCross Validation Acc: 0.8125\n",
      "Epoch: 79\tTraining Error: 147.508056819\tCross Validation Acc: 0.812681686047\n",
      "Epoch: 80\tTraining Error: 147.003964961\tCross Validation Acc: 0.813226744186\n",
      "Epoch: 81\tTraining Error: 146.50798583\tCross Validation Acc: 0.813953488372\n",
      "Epoch: 82\tTraining Error: 146.019891918\tCross Validation Acc: 0.814316860465\n",
      "Epoch: 83\tTraining Error: 145.539458334\tCross Validation Acc: 0.814680232558\n",
      "Epoch: 84\tTraining Error: 145.066477537\tCross Validation Acc: 0.815043604651\n",
      "Epoch: 85\tTraining Error: 144.600737393\tCross Validation Acc: 0.815406976744\n",
      "Epoch: 86\tTraining Error: 144.142052531\tCross Validation Acc: 0.815406976744\n",
      "Epoch: 87\tTraining Error: 143.690229416\tCross Validation Acc: 0.81613372093\n",
      "Epoch: 88\tTraining Error: 143.245076358\tCross Validation Acc: 0.81613372093\n",
      "Epoch: 89\tTraining Error: 142.806420803\tCross Validation Acc: 0.816315406977\n",
      "Epoch: 90\tTraining Error: 142.374092519\tCross Validation Acc: 0.817042151163\n",
      "Epoch: 91\tTraining Error: 141.947918534\tCross Validation Acc: 0.817405523256\n",
      "Epoch: 92\tTraining Error: 141.527746677\tCross Validation Acc: 0.818313953488\n",
      "Epoch: 93\tTraining Error: 141.113410354\tCross Validation Acc: 0.818495639535\n",
      "Epoch: 94\tTraining Error: 140.704767466\tCross Validation Acc: 0.818495639535\n",
      "Epoch: 95\tTraining Error: 140.301679611\tCross Validation Acc: 0.818495639535\n",
      "Epoch: 96\tTraining Error: 139.903990567\tCross Validation Acc: 0.818313953488\n",
      "Epoch: 97\tTraining Error: 139.511578083\tCross Validation Acc: 0.818859011628\n",
      "Epoch: 98\tTraining Error: 139.124310017\tCross Validation Acc: 0.819222383721\n",
      "Epoch: 99\tTraining Error: 138.74205792\tCross Validation Acc: 0.818859011628\n",
      "Epoch: 100\tTraining Error: 138.364700735\tCross Validation Acc: 0.819585755814\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter('./graphs',sess.graph)\n",
    "    epoch_data = {'training_error':[],'validation_acc':[]}\n",
    "    for epoch in range(n_epochs):\n",
    "        acc,error = [],0\n",
    "        for i in range(num_training_data/batch_size):\n",
    "            cur_batch = i*batch_size\n",
    "            next_batch = (i+1)*batch_size\n",
    "            x_batch,y_batch = X_train[cur_batch:next_batch,:],y_train[cur_batch:next_batch,:]\n",
    "            _,l = sess.run([optimizer,loss],feed_dict = {X:x_batch,y:y_batch})\n",
    "            error += l\n",
    "        for i in range(num_training_data_cv/batch_size):\n",
    "            cur_batch = i*batch_size\n",
    "            next_batch = (i+1)*batch_size\n",
    "            x_batch,y_batch = X_test[cur_batch:next_batch,:],y_test[cur_batch:next_batch,:]\n",
    "            predictions = sess.run(ypred,feed_dict = {X:x_batch,y:y_batch})\n",
    "            correct_labels = np.argmax(y_batch,axis=1)\n",
    "            correct_predictions = np.argmax(predictions,axis=1)\n",
    "            acc.append(np.mean(np.equal(correct_labels,correct_predictions)))\n",
    "        print 'Epoch: {}\\tTraining Error: {}\\tCross Validation Acc: {}'.format(epoch+1,error,np.mean(acc))\n",
    "        epoch_data['training_error'].append(error)\n",
    "        epoch_data['validation_acc'].append(np.mean(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11e7bc6d0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArQAAAHcCAYAAAAncTlwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x128a4fe10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_data['training_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x128a4fe50>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqgAAAHcCAYAAAAa41gWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x128b3de50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_data['validation_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Neural Network to predict Coronary Heart Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462, 10)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../../Dataset/heart.csv')\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>chd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>Present</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>Absent</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sbp  tobacco   ldl  adiposity  famhist  typea  obesity  alcohol  age  chd\n",
       "0  160    12.00  5.73      23.11  Present     49    25.30    97.20   52    1\n",
       "1  144     0.01  4.41      28.61   Absent     55    28.87     2.06   63    1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(462, 11)\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    if data[col].dtype == 'object':\n",
    "        data = pd.concat([data,pd.get_dummies(data[col])],axis=1)\n",
    "        data.pop(col)\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>chd</th>\n",
       "      <th>Absent</th>\n",
       "      <th>Present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sbp  tobacco   ldl  adiposity  typea  obesity  alcohol  age  chd  Absent  \\\n",
       "0  160    12.00  5.73      23.11     49    25.30    97.20   52    1     0.0   \n",
       "1  144     0.01  4.41      28.61     55    28.87     2.06   63    1     1.0   \n",
       "\n",
       "   Present  \n",
       "0      1.0  \n",
       "1      0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(323, 10) (323, 2)\n"
     ]
    }
   ],
   "source": [
    "label = data.pop('chd')\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(data,pd.get_dummies(label),test_size=0.3,random_state=7)\n",
    "print X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "num_hidden_layer = 256\n",
    "n_training,num_features = X_train.shape\n",
    "n_cv = X_test.shape[0]\n",
    "batch_size = 128\n",
    "num_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(dtype=tf.float32,shape=[batch_size,num_features],name='X')\n",
    "y = tf.placeholder(dtype=tf.float32,shape=[batch_size,num_classes],name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W1 = tf.get_variable(name='W1',shape=[num_features,num_hidden_layer],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.ones([1,num_hidden_layer]),name='b1')\n",
    "W2 = tf.get_variable(name='W2',shape=[num_hidden_layer,num_classes],initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.ones([1,num_classes]),name='b2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a1 = tf.nn.relu(tf.matmul(X,W1) + b1)\n",
    "logits = tf.matmul(a1,W2) + b2\n",
    "ypred = tf.arg_max(logits,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=logits))\n",
    "optimizer = tf.train.AdadeltaOptimizer(learning_rate=0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tTraining Loss: 3.2473692894\tCV Accuracy: 0.515625\n",
      "Epoch: 2\tTraining Loss: 3.23972940445\tCV Accuracy: 0.515625\n",
      "Epoch: 3\tTraining Loss: 3.23294472694\tCV Accuracy: 0.515625\n",
      "Epoch: 4\tTraining Loss: 3.22640311718\tCV Accuracy: 0.515625\n",
      "Epoch: 5\tTraining Loss: 3.21997928619\tCV Accuracy: 0.515625\n",
      "Epoch: 6\tTraining Loss: 3.21362519264\tCV Accuracy: 0.515625\n",
      "Epoch: 7\tTraining Loss: 3.20731818676\tCV Accuracy: 0.515625\n",
      "Epoch: 8\tTraining Loss: 3.20103597641\tCV Accuracy: 0.515625\n",
      "Epoch: 9\tTraining Loss: 3.19477772713\tCV Accuracy: 0.515625\n",
      "Epoch: 10\tTraining Loss: 3.18853855133\tCV Accuracy: 0.515625\n",
      "Epoch: 11\tTraining Loss: 3.18231296539\tCV Accuracy: 0.515625\n",
      "Epoch: 12\tTraining Loss: 3.17609810829\tCV Accuracy: 0.515625\n",
      "Epoch: 13\tTraining Loss: 3.16988706589\tCV Accuracy: 0.515625\n",
      "Epoch: 14\tTraining Loss: 3.16369342804\tCV Accuracy: 0.515625\n",
      "Epoch: 15\tTraining Loss: 3.1575063467\tCV Accuracy: 0.5234375\n",
      "Epoch: 16\tTraining Loss: 3.15132772923\tCV Accuracy: 0.5234375\n",
      "Epoch: 17\tTraining Loss: 3.14514708519\tCV Accuracy: 0.5234375\n",
      "Epoch: 18\tTraining Loss: 3.13898563385\tCV Accuracy: 0.5234375\n",
      "Epoch: 19\tTraining Loss: 3.13283419609\tCV Accuracy: 0.5234375\n",
      "Epoch: 20\tTraining Loss: 3.12669074535\tCV Accuracy: 0.5234375\n",
      "Epoch: 21\tTraining Loss: 3.12055385113\tCV Accuracy: 0.5234375\n",
      "Epoch: 22\tTraining Loss: 3.11442840099\tCV Accuracy: 0.5234375\n",
      "Epoch: 23\tTraining Loss: 3.10832428932\tCV Accuracy: 0.5234375\n",
      "Epoch: 24\tTraining Loss: 3.10222887993\tCV Accuracy: 0.5234375\n",
      "Epoch: 25\tTraining Loss: 3.09614014626\tCV Accuracy: 0.5234375\n",
      "Epoch: 26\tTraining Loss: 3.09006178379\tCV Accuracy: 0.5234375\n",
      "Epoch: 27\tTraining Loss: 3.08399498463\tCV Accuracy: 0.5234375\n",
      "Epoch: 28\tTraining Loss: 3.07793796062\tCV Accuracy: 0.5234375\n",
      "Epoch: 29\tTraining Loss: 3.07188951969\tCV Accuracy: 0.515625\n",
      "Epoch: 30\tTraining Loss: 3.06584119797\tCV Accuracy: 0.5078125\n",
      "Epoch: 31\tTraining Loss: 3.0598013401\tCV Accuracy: 0.5078125\n",
      "Epoch: 32\tTraining Loss: 3.05376708508\tCV Accuracy: 0.5078125\n",
      "Epoch: 33\tTraining Loss: 3.04773545265\tCV Accuracy: 0.5078125\n",
      "Epoch: 34\tTraining Loss: 3.04170441628\tCV Accuracy: 0.5078125\n",
      "Epoch: 35\tTraining Loss: 3.03567683697\tCV Accuracy: 0.5078125\n",
      "Epoch: 36\tTraining Loss: 3.0296523571\tCV Accuracy: 0.5078125\n",
      "Epoch: 37\tTraining Loss: 3.02362215519\tCV Accuracy: 0.5078125\n",
      "Epoch: 38\tTraining Loss: 3.01760363579\tCV Accuracy: 0.5078125\n",
      "Epoch: 39\tTraining Loss: 3.01159727573\tCV Accuracy: 0.5078125\n",
      "Epoch: 40\tTraining Loss: 3.0056078434\tCV Accuracy: 0.5078125\n",
      "Epoch: 41\tTraining Loss: 2.99963009357\tCV Accuracy: 0.5078125\n",
      "Epoch: 42\tTraining Loss: 2.99365246296\tCV Accuracy: 0.5078125\n",
      "Epoch: 43\tTraining Loss: 2.98767399788\tCV Accuracy: 0.5078125\n",
      "Epoch: 44\tTraining Loss: 2.98170566559\tCV Accuracy: 0.5078125\n",
      "Epoch: 45\tTraining Loss: 2.97574698925\tCV Accuracy: 0.5078125\n",
      "Epoch: 46\tTraining Loss: 2.96979415417\tCV Accuracy: 0.5078125\n",
      "Epoch: 47\tTraining Loss: 2.96383452415\tCV Accuracy: 0.5078125\n",
      "Epoch: 48\tTraining Loss: 2.95788383484\tCV Accuracy: 0.5078125\n",
      "Epoch: 49\tTraining Loss: 2.95194280148\tCV Accuracy: 0.5078125\n",
      "Epoch: 50\tTraining Loss: 2.94601035118\tCV Accuracy: 0.5078125\n",
      "Epoch: 51\tTraining Loss: 2.94008743763\tCV Accuracy: 0.5078125\n",
      "Epoch: 52\tTraining Loss: 2.93417704105\tCV Accuracy: 0.5078125\n",
      "Epoch: 53\tTraining Loss: 2.92828822136\tCV Accuracy: 0.515625\n",
      "Epoch: 54\tTraining Loss: 2.92241382599\tCV Accuracy: 0.515625\n",
      "Epoch: 55\tTraining Loss: 2.91655230522\tCV Accuracy: 0.515625\n",
      "Epoch: 56\tTraining Loss: 2.91069936752\tCV Accuracy: 0.515625\n",
      "Epoch: 57\tTraining Loss: 2.90485906601\tCV Accuracy: 0.5\n",
      "Epoch: 58\tTraining Loss: 2.89904785156\tCV Accuracy: 0.5\n",
      "Epoch: 59\tTraining Loss: 2.89324533939\tCV Accuracy: 0.5\n",
      "Epoch: 60\tTraining Loss: 2.88746345043\tCV Accuracy: 0.5078125\n",
      "Epoch: 61\tTraining Loss: 2.88169920444\tCV Accuracy: 0.5078125\n",
      "Epoch: 62\tTraining Loss: 2.87592697144\tCV Accuracy: 0.515625\n",
      "Epoch: 63\tTraining Loss: 2.87014997005\tCV Accuracy: 0.515625\n",
      "Epoch: 64\tTraining Loss: 2.86438262463\tCV Accuracy: 0.515625\n",
      "Epoch: 65\tTraining Loss: 2.85862374306\tCV Accuracy: 0.515625\n",
      "Epoch: 66\tTraining Loss: 2.85286402702\tCV Accuracy: 0.515625\n",
      "Epoch: 67\tTraining Loss: 2.84710407257\tCV Accuracy: 0.515625\n",
      "Epoch: 68\tTraining Loss: 2.84134852886\tCV Accuracy: 0.515625\n",
      "Epoch: 69\tTraining Loss: 2.83559858799\tCV Accuracy: 0.515625\n",
      "Epoch: 70\tTraining Loss: 2.82985174656\tCV Accuracy: 0.515625\n",
      "Epoch: 71\tTraining Loss: 2.82411324978\tCV Accuracy: 0.515625\n",
      "Epoch: 72\tTraining Loss: 2.81838297844\tCV Accuracy: 0.515625\n",
      "Epoch: 73\tTraining Loss: 2.81265997887\tCV Accuracy: 0.515625\n",
      "Epoch: 74\tTraining Loss: 2.80693089962\tCV Accuracy: 0.515625\n",
      "Epoch: 75\tTraining Loss: 2.80123245716\tCV Accuracy: 0.515625\n",
      "Epoch: 76\tTraining Loss: 2.79553961754\tCV Accuracy: 0.515625\n",
      "Epoch: 77\tTraining Loss: 2.78984940052\tCV Accuracy: 0.515625\n",
      "Epoch: 78\tTraining Loss: 2.78418648243\tCV Accuracy: 0.515625\n",
      "Epoch: 79\tTraining Loss: 2.77853214741\tCV Accuracy: 0.515625\n",
      "Epoch: 80\tTraining Loss: 2.77288627625\tCV Accuracy: 0.515625\n",
      "Epoch: 81\tTraining Loss: 2.76725304127\tCV Accuracy: 0.515625\n",
      "Epoch: 82\tTraining Loss: 2.76162838936\tCV Accuracy: 0.515625\n",
      "Epoch: 83\tTraining Loss: 2.75600385666\tCV Accuracy: 0.5234375\n",
      "Epoch: 84\tTraining Loss: 2.75037229061\tCV Accuracy: 0.5234375\n",
      "Epoch: 85\tTraining Loss: 2.74474561214\tCV Accuracy: 0.5234375\n",
      "Epoch: 86\tTraining Loss: 2.73913168907\tCV Accuracy: 0.515625\n",
      "Epoch: 87\tTraining Loss: 2.73353970051\tCV Accuracy: 0.515625\n",
      "Epoch: 88\tTraining Loss: 2.72796165943\tCV Accuracy: 0.515625\n",
      "Epoch: 89\tTraining Loss: 2.72239565849\tCV Accuracy: 0.515625\n",
      "Epoch: 90\tTraining Loss: 2.71683764458\tCV Accuracy: 0.515625\n",
      "Epoch: 91\tTraining Loss: 2.71128892899\tCV Accuracy: 0.515625\n",
      "Epoch: 92\tTraining Loss: 2.70575869083\tCV Accuracy: 0.515625\n",
      "Epoch: 93\tTraining Loss: 2.70023047924\tCV Accuracy: 0.515625\n",
      "Epoch: 94\tTraining Loss: 2.69471788406\tCV Accuracy: 0.515625\n",
      "Epoch: 95\tTraining Loss: 2.68922758102\tCV Accuracy: 0.515625\n",
      "Epoch: 96\tTraining Loss: 2.68374681473\tCV Accuracy: 0.515625\n",
      "Epoch: 97\tTraining Loss: 2.67826080322\tCV Accuracy: 0.515625\n",
      "Epoch: 98\tTraining Loss: 2.67277872562\tCV Accuracy: 0.515625\n",
      "Epoch: 99\tTraining Loss: 2.66730749607\tCV Accuracy: 0.515625\n",
      "Epoch: 100\tTraining Loss: 2.66183125973\tCV Accuracy: 0.515625\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter('./graphs',sess.graph)\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss,epoch_cv_acc = 0,[]\n",
    "        for batch in iterate_minibatches(X_train,y_train,batch_size,shuffle=False):\n",
    "            x_batch,y_batch = batch\n",
    "            _,l = sess.run([optimizer,loss],feed_dict={X:x_batch,y:y_batch})\n",
    "            epoch_loss += l\n",
    "        for batch in iterate_minibatches(X_test,y_test,batch_size,shuffle=False):\n",
    "            x_batch,y_batch = batch\n",
    "            predictions = sess.run(ypred,feed_dict={X:x_batch,y:y_batch})\n",
    "            epoch_cv_acc.append(np.mean(np.equal(predictions,np.argmax(y_batch))))\n",
    "        print 'Epoch: {}\\tTraining Loss: {}\\tCV Accuracy: {}'.format(epoch+1,epoch_loss,np.mean(epoch_cv_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Don't Predict, Count!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified text8.zip\n"
     ]
    }
   ],
   "source": [
    "from embeddings_data import *\n",
    "filename = maybe_download('text8.zip', 31344016)\n",
    "words = read_data('/Users/najeebkhan/Downloads/text8 (1).zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = [' '.join(words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmatrix = cv.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10000)\n"
     ]
    }
   ],
   "source": [
    "print cmatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = cmatrix.T * cmatrix\n",
    "X.setdiag(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10000)\n"
     ]
    }
   ],
   "source": [
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_mat = tf.Variable(initial_value=X.todense(),name=\"cooccurence\",dtype=tf.float32)\n",
    "S = tf.svd(input_mat,compute_uv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    s = sess.run(S)\n",
    "    print s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.01833e+12\n"
     ]
    }
   ],
   "source": [
    "print s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
