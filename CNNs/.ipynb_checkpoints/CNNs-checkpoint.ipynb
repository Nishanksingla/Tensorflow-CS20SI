{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.next_batch(100)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_training_size,n_features = mnist.train.images.shape\n",
    "n_test_size = mnist.test.images.shape[0]\n",
    "batch_size = 100\n",
    "n_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of the Model\n",
    "![Alt text](layers.png \"Structure of Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"input\") as scope:\n",
    "    image = tf.placeholder(dtype=tf.float32,shape=[None,28,28,1],name=\"image\")\n",
    "    y = tf.placeholder(dtype=tf.float32,shape=[None,10],name=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"conv1\") as scope:\n",
    "    w = tf.get_variable(name=\"weights\",shape=[5,5,1,32],initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    b = tf.get_variable(name=\"biases\",shape=[32],initializer=tf.random_normal_initializer())\n",
    "    conv = tf.nn.conv2d(image,w,strides=[1,1,1,1],padding=\"SAME\")\n",
    "    relu = tf.nn.relu(conv+b,name=scope.name)\n",
    "    conv1 = tf.nn.max_pool(relu,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"conv2\") as scope:\n",
    "    w = tf.get_variable(name=\"weights\",shape=[5,5,32,64],initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    b = tf.get_variable(name=\"biases\",shape=[64],initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "    conv = tf.nn.conv2d(conv1,w,strides=[1,1,1,1],padding=\"SAME\")\n",
    "    relu = tf.nn.relu(conv+b,name=scope.name)\n",
    "    conv2 = tf.nn.max_pool(relu,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"full\") as scope:\n",
    "    w = tf.get_variable(name=\"weights\",shape=[7*7*64,1024],initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b = tf.get_variable(name=\"biases\",shape=[1024],initializer=tf.random_normal_initializer())\n",
    "    flat = tf.reshape(conv2,[-1,7*7*64])\n",
    "    full = tf.nn.relu(tf.matmul(flat,w) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"dropout\") as scope:\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    drop = tf.nn.dropout(full,keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"softmax\") as scope:\n",
    "    w = tf.get_variable(name=\"weights\",shape=[1024,10],initializer=tf.contrib.layers.xavier_initializer())\n",
    "    b = tf.get_variable(name=\"biases\",shape=[10],initializer=tf.random_normal_initializer())\n",
    "    out = tf.nn.softmax(tf.matmul(drop,w)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\") as scope:\n",
    "    loss = tf.reduce_mean(-tf.reduce_sum(y*tf.log(out),reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"optimizer\") as scope:\n",
    "    optimizer = tf.train.AdagradOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"predictions\") as scope:\n",
    "    correct_preds = tf.equal(tf.arg_max(out,1),tf.arg_max(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_preds,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\tLoss: 450.142312631\tAccuracy: 0.729963636398\n",
      "Epoch: 1\tLoss: 105.262174346\tAccuracy: 0.941345456947\n",
      "Epoch: 2\tLoss: 72.5997081511\tAccuracy: 0.959054550366\n",
      "Epoch: 3\tLoss: 58.3142517637\tAccuracy: 0.966181824966\n",
      "Epoch: 4\tLoss: 49.2931561125\tAccuracy: 0.971890917475\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "n_batches = n_training_size/batch_size\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter('graphs/',sess.graph)\n",
    "    for i in range(n_epochs):\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        for j in range(n_batches):\n",
    "            x_batch,y_batch = mnist.train.next_batch(100)\n",
    "            x_batch = np.reshape(x_batch,(100,28,28,1))\n",
    "            _,l,acc = sess.run([optimizer,loss,accuracy],feed_dict={image:x_batch,y:y_batch,keep_prob:0.5})\n",
    "            epoch_loss += l\n",
    "            epoch_accuracy += acc\n",
    "        print 'Epoch: {}\\tLoss: {}\\tAccuracy: {}'.format(i,epoch_loss,epoch_accuracy/n_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Computational Graph](graph.png \"Tensorboard Graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "04e020ef4c0841c6b4a638a0eb8767ee": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "1d9a9c36666240c4b6f64be2886924e2": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "2daa5b1b986e41669823cc7db659866e": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "34ddd9e87b1c441cbd3d5f96cee7386a": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "37619faa3ada472cbbeb567b345d926c": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "5a0ba14197534553b0220ba1616104b9": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "5ae82ef4c1c74bbf9e82f271bd945bae": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "5cacad273629475a982eb54827fdefa6": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "65ebbac325d14017b41566682f8e9b5c": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "762151e176f24c8da2dff1f781fb7535": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "78c73f783323423c951051e3f6ee5860": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "7ab1751ead4c41d4871a99a21ec8f98b": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "863b4d4395194e11a211a020f9edbf03": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "896908d8a22a49e3bb296f5b327f67c8": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "8bae63cedcb24e5980f26d5bf3a6bca4": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "95ab12e4edb0429e8e97c7b7de2296bd": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "9f7116f98a694ad9ab8a04e92061bb1d": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "a07e640ccdd644cf9af24981e0b8903a": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "b04aa0dc784842f29d1988f95fb29d9f": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "b7c917d89918414db79a2669f36da64c": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "ba5a44f816ea4a1a916e9373743b28fc": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "bbdfa19ad70541eea31c4118e39c0563": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "c4e198a7472d4537943c41c6373d6cfd": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "d2832e9bc0a14e03a087f555085c134f": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "d3cc922e652a4c5ebabe32942d6ca97f": {
     "views": [
      {
       "cell_index": 19
      },
      {
       "cell_index": 19
      },
      {
       "cell_index": 19
      },
      {
       "cell_index": 19
      },
      {
       "cell_index": 19
      },
      {
       "cell_index": 19
      }
     ]
    },
    "d670cb07f90748319c4706e6f629ae98": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "ea4fc5fbc2bd4d21ab1a36b5e7bea942": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "f60df2baec2e4404a06127bc82b97b1d": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
